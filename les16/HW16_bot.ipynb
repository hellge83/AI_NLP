{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3313dfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce0ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from telegram import Update\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "\n",
    "import dialogflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d89f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9edb6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2-sv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a032ca21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['когда приходит понедельник',\n",
       " 'cперва жена моя сбежала',\n",
       " 'я женщинам не доверяю',\n",
       " 'в наш век высоких технологий',\n",
       " 'с утра немного поработал',\n",
       " 'у губернатора дилемма',\n",
       " 'аркадий не любил пробежки',\n",
       " 'татарский хан сурово крикнул',\n",
       " 'плохой купил ты телевизор',\n",
       " 'сломаться может всё на свете']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('starters.txt', 'r', encoding = 'utf-8') as f:\n",
    "    starters = f.read().strip().split('\\n')\n",
    "starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9ba49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(prefix):\n",
    "    end_token_id = tokenizer.encode('***')[0]\n",
    "    tokens = tokenizer(prefix, return_tensors='pt')\n",
    "    tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
    "    size = tokens['input_ids'].shape[1]\n",
    "    output = model.generate(\n",
    "        **tokens, \n",
    "        end_token=end_token_id,\n",
    "        do_sample=False, \n",
    "        max_length=size+60, \n",
    "        repetition_penalty=10., \n",
    "        temperature=1,\n",
    "        num_beams=10,\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0])\n",
    "    result = decoded[len(prefix):]\n",
    "    result1 = prefix + result.split('\\n')[0]\n",
    "    result2 = result.split('\\n')[2]\n",
    "\n",
    "    return '\\n\\n***BONUS***\\n'.join([result1, result2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa60a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "когда приходит понедельник я открываю холодильник и вижу там говна столько что мне бы хватило до середины февраля\n",
      "\n",
      "***BONUS***\n",
      "олег в костюме супермэна пришёл на первое свиданье с оксаной а у неё план по спасению утопающих мужыков\n"
     ]
    }
   ],
   "source": [
    "print(get_answer(starters[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ef506",
   "metadata": {},
   "source": [
    "### bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "696d7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "!set GOOGLE_APPLICATION_CREDENTIALS = 'D:/GeekBrains/nlp/les15/ai-nlp-bot-9nju.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89981012",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALOGFLOW_PROJECT_ID = 'ai-nlp-bot-9nju' #PROJECT ID из DialogFlow \n",
    "DIALOGFLOW_LANGUAGE_CODE = 'ru' # язык\n",
    "SESSION_ID = 'ai_oleg_story_bot'  # ID бота из телеграма\n",
    "TOKEN = \"1950225126:AAEpyzTBshSCeWJRBNYq3DKEAbRhFy2BmGA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3579392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'D:/GeekBrains/nlp/les15/ai-nlp-bot-9nju.json'# скачнный JSON\n",
    "updater = Updater(TOKEN, use_context=True)  # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc889ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startCommand(update: Update, context: CallbackContext):\n",
    "    update.message.reply_text('какой стишок ты хочешь?')\n",
    "\n",
    "    \n",
    "def textMessage(update: Update, context: CallbackContext):\n",
    "    session_client = dialogflow.SessionsClient()\n",
    "    session = session_client.session_path(DIALOGFLOW_PROJECT_ID, SESSION_ID)\n",
    "    \n",
    "    text_input = update.message.text\n",
    "    if text_input == 'start':\n",
    "        update.message.reply_text('скажи первую строчку')\n",
    "    else:\n",
    "        update.message.reply_text(get_answer(text_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "820e4995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "dispatcher.add_handler(CommandHandler('start', startCommand))\n",
    "dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, textMessage))\n",
    "# Начинаем поиск обновлений\n",
    "updater.start_polling()\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
