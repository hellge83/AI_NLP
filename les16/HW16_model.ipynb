{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7f692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fce1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac013f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507000d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8970\n",
      "–∞ –≥–¥–µ —Ç—É—Ç —Ä—É–ª—å —Å–ø—Ä–æ—Å–∏–ª –≥–∞–≥–∞—Ä–∏–Ω –¥–µ—Ä–µ–≤–Ω—è –±—É—Ä–∫–Ω—É–ª –∫–æ—Ä–æ–ª—ë–≤ –µ—â—ë —Å–ø—Ä–æ—Å–∏ –∞ –≥–¥–µ —Ç—É—Ç –≤–æ–∂–∂–∏ –µ—â—ë –ø–æ–µ—Ö–∞–ª–∏ —Å–∫–∞–∂–∏\n",
      "–≤–æ—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π –∞–Ω–∞—Ç–æ–ª–∏–π –±—ã–ª –ø–æ—Å–ª–∞–Ω –Ω–∞—Ö—É–π –Ω–æ —Å—É–º–µ–ª –≤–µ—Ä–Ω—É—Ç—å—Å—è –±–æ–¥—Ä—ã–º –æ—Ç–¥–æ—Ö–Ω—É–≤—à–∏–º –∏ –¥–≤–∞ –º–∞–≥–Ω–∏—Ç–∏–∫–∞ –ø—Ä–∏–≤–µ–∑\n",
      "–ø–µ—Ä–µ–¥ –æ–∫—Å–∞–Ω–æ–π –≤ —Ç—ë–º–Ω–æ–º –ø–∞—Ä–∫–µ –æ–ª–µ–≥ —Ä–∞—Å–ø–∞—Ö–∏–≤–∞–µ—Ç –ø–ª–∞—â –ø–æ–¥ –Ω–∏–º –≤—Ç–æ—Ä–æ–π –∞ –¥–∞–ª—å—à–µ —Ç—Ä–µ—Ç–∏–π –æ–∫—Å–∞–Ω–∞ —Ç–µ—Ä–ø–µ–ª–∏–≤–æ –∂–¥—ë—Ç\n"
     ]
    }
   ],
   "source": [
    "with open('poems.txt', 'r', encoding = 'utf-8') as f:\n",
    "    poems = f.read().strip().split('\\n')\n",
    "print(len(poems))\n",
    "for i in range(3):\n",
    "    print(poems[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730a4d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       –∞ –≥–¥–µ —Ç—É—Ç —Ä—É–ª—å —Å–ø—Ä–æ—Å–∏–ª –≥–∞–≥–∞—Ä–∏–Ω –¥–µ—Ä–µ–≤–Ω—è –±—É—Ä–∫–Ω—É–ª...\n",
       "1       –≤–æ—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π –∞–Ω–∞—Ç–æ–ª–∏–π –±—ã–ª –ø–æ—Å–ª–∞–Ω –Ω–∞—Ö—É–π –Ω–æ —Å—É...\n",
       "2       –ø–µ—Ä–µ–¥ –æ–∫—Å–∞–Ω–æ–π –≤ —Ç—ë–º–Ω–æ–º –ø–∞—Ä–∫–µ –æ–ª–µ–≥ —Ä–∞—Å–ø–∞—Ö–∏–≤–∞–µ—Ç ...\n",
       "3       –∞ –ª—é–±–∏—à—å —Ä–æ–ª–µ–≤—ã–µ –∏–≥—Ä—ã —Ç–µ–±–µ –∫–æ–≥–æ –∏–∑–æ–±—Ä–∞–∑–∏—Ç—å –∏–∑–æ...\n",
       "4       —Å–ø–µ—Ä–≤–∞ –∂–µ–Ω–∞ –º–æ—è —Å–±–µ–∂–∞–ª–∞ –ø–æ—Ç–æ–º —Å–æ–±–∞–∫–∞ –∏ –∫–æ—Ç—ã —Å–µ...\n",
       "                              ...                        \n",
       "8965    —Å–µ–π—á–∞—Å –Ω–∞—á–∞–ª–æ –¥–µ–≤—è–Ω–æ—Å—Ç—ã—Ö –ª—é–±–µ –µ—â–æ –ø–æ—á—Ç–∏ –ø–æ—Å—Ç–ø–∞...\n",
       "8966    –≤–ø–∏—Ö–Ω—É–ª–∏ –≤ —Ç–µ—Å–Ω—É—é –≤ –æ–±–æ–π–º—É –ø–∏–Ω–∫–æ–º –ø–æ–≥–Ω–∞–ª–∏ –ø–æ —Å...\n",
       "8967    –æ–¥–Ω–∞–∂–¥—ã —è —Å–∏–¥–µ–ª –Ω–∞ –∫—Ä—ã—à–µ –∞ —Ç—ã —Å–∏–¥–µ–ª–∞ –Ω–∞ —Ç—Ä—É–±–µ ...\n",
       "8968    —Å–∫–æ—Ä–µ–π –æ–¥–µ–Ω—å—Ç–µ—Å—å –∑–∏–Ω–∞–∏–¥–∞ —è –≤–∞—Å –æ–±—Ä–∞–¥–æ–≤–∞—Ç—å —Ö–æ—á—É...\n",
       "8969    –∑–µ—Ä–∫–∞–ª —Ç–∞–º –Ω–µ –±—ã–ª–æ –∫–æ–Ω–µ—á–Ω–æ –∑–∞—Ç–æ –≤–∏—Å–µ–ª –ø–æ—Ä—Ç—Ä–µ—Ç ...\n",
       "Length: 8970, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.Series(poems)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e0ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_files(data_json, dest_path):\n",
    "    f = open(dest_path, 'w', encoding=\"utf-8\")\n",
    "    data = ''\n",
    "    for texts in data_json:\n",
    "        summary = str(texts).strip()\n",
    "        summary = re.sub(r\"\\s\", \" \", summary)\n",
    "        data += summary + '\\n***\\n'\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c8e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.15)\n",
    "\n",
    "build_text_files(train,'train_dataset.txt')\n",
    "build_text_files(test,'test_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7821d749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "\n",
    "train_path = 'train_dataset.txt'\n",
    "test_path = 'test_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f536179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path, test_path, tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=64)\n",
    "\n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=64)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset, test_dataset, data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e30282c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f75e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f31338e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-sv\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=6, # number of training epochs\n",
    "    per_device_train_batch_size=2, # batch size for training\n",
    "    per_device_eval_batch_size=2,  # batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations.\n",
    "    save_steps=800, # after # steps model is saved\n",
    "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "#     eval_accumulation_steps=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07fcb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9999432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3118\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9354\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9354' max='9354' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9354/9354 32:06, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.684300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.584800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.887600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.875600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.361900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.274300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.893600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.716400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.746700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.068700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-800\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-800\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-800\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-1600\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-1600\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-2400\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-2400\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-3200\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-3200\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-4000\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-4000\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-4000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-4800\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-4800\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-4800\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-5600\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-5600\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-5600\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-6400\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-6400\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-6400\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-7200\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-7200\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-7200\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-8000\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-8000\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-8000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./gpt2-sv\\checkpoint-8800\n",
      "Configuration saved in ./gpt2-sv\\checkpoint-8800\\config.json\n",
      "Model weights saved in ./gpt2-sv\\checkpoint-8800\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9354, training_loss=3.135846999100903, metrics={'train_runtime': 1927.2976, 'train_samples_per_second': 9.707, 'train_steps_per_second': 4.853, 'total_flos': 611031416832000.0, 'train_loss': 3.135846999100903, 'epoch': 6.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4dc28f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./gpt2-sv\n",
      "Configuration saved in ./gpt2-sv\\config.json\n",
      "Model weights saved in ./gpt2-sv\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61bab17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_token_id = tokenizer.encode('***')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bd7a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å –∫–∞–ø–µ–ª—å –Ω–∏–∫–æ—Ç–∏–Ω–∞ \"\n",
    "tokens = tokenizer(prefix, return_tensors='pt')\n",
    "tokens = {k: v.to(model.device) for k, v in tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c07a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å –∫–∞–ø–µ–ª—å –Ω–∏–∫–æ—Ç–∏–Ω–∞ —â–∏–ø–ª–µ—Ç —É –≤–∏—à–Ω–∏ –Ω–∏–∫–æ–ª–∞—è –¥–≤–∞ –∂–µ–ª–∞–Ω—å—è –æ–¥–Ω–∞ –æ–ª—å–≥–∞ –¥—Ä—É–≥–∞—è –ø–µ—Ç—Ä\n",
      "***\n",
      "–≤–µ–Ω–∏–∞–º–∏–Ω –ª–µ–∂–∏—Ç –Ω–∞ –∞—Å—Ñ–∞–ª—å—Ç–µ –∏ –¥–æ–∂–¥—å –∏–∑ –∫–∞–Ω–∏—Ñ–æ–ª—å—é —Å—Ç–µ–∫–∞–µ—Ç –ø–æ –ª–∏—Ü—É —Ç–∞–∫ –Ω–µ–∑–∞–º–µ—Ç–Ω–æ —á—Ç–æ –æ–Ω —É–∂–µ –Ω–µ –º—ã—Å–ª–∏—Ç –Ω–∏ –æ —á—ë–º\n",
      "***\n",
      "–æ–ª–µ–≥ –∫—É–ø–∏–ª –≤ –∫–∏–æ—Å–∫–µ\n"
     ]
    }
   ],
   "source": [
    "size = tokens['input_ids'].shape[1]\n",
    "output = model.generate(\n",
    "    **tokens, \n",
    "    end_token=end_token_id,\n",
    "    do_sample=False, \n",
    "    max_length=size+60, \n",
    "    repetition_penalty=10., \n",
    "    temperature=1,\n",
    "    num_beams=10,\n",
    ")\n",
    "\n",
    "decoded = tokenizer.decode(output[0])\n",
    "result = decoded[len(prefix):]\n",
    "print(prefix + result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d25de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f44c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3faa8bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = \"—Ç—Ä–∏–Ω–∞–¥—Ü–∞—Ç—å –∫–∞–ø–µ–ª—å –Ω–∏–∫–æ—Ç–∏–Ω–∞ \"\n",
    "# tokens = tokenizer(prefix, return_tensors='pt')\n",
    "# tokens = {k: v.to(model.device) for k, v in tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88268bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = tokens['input_ids'].shape[1]\n",
    "# output = model.generate(\n",
    "#     **tokens, \n",
    "#     end_token=end_token_id,\n",
    "#     do_sample=False, \n",
    "#     max_length=size+50, \n",
    "#     repetition_penalty=5., \n",
    "#     temperature=0.5,\n",
    "#     num_beams=10,\n",
    "# )\n",
    "\n",
    "# decoded = tokenizer.decode(output[0])\n",
    "# result = decoded[len(prefix):]\n",
    "# print(prefix + result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0695d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()\n",
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea26a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = \"–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã –∑–Ω–∞–∫–æ–º—ã —Å –æ–ª—å–≥–æ–π \"\n",
    "# tokens = tokenizer(prefix, return_tensors='pt')\n",
    "# tokens = {k: v.to(model.device) for k, v in tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e8c3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = tokens['input_ids'].shape[1]\n",
    "# output = model.generate(\n",
    "#     **tokens, \n",
    "#     end_token=end_token_id,\n",
    "#     do_sample=False, \n",
    "#     max_length=size+50, \n",
    "#     repetition_penalty=10., \n",
    "#     temperature=10.,\n",
    "#     num_beams=10,\n",
    "# )\n",
    "\n",
    "# decoded = tokenizer.decode(output[0])\n",
    "# result = decoded[len(prefix):]\n",
    "# print(prefix + result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a81a863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()\n",
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5393e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = \"–æ–∫—Å–∞–Ω–∞ —Ä–∞–¥–æ—Å—Ç–Ω–æ –∑–∞–ø–µ–ª–∞ \"\n",
    "# tokens = tokenizer(prefix, return_tensors='pt')\n",
    "# tokens = {k: v.to(model.device) for k, v in tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14196d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = tokens['input_ids'].shape[1]\n",
    "# output = model.generate(\n",
    "#     **tokens, \n",
    "#     end_token=end_token_id,\n",
    "#     do_sample=False, \n",
    "#     max_length=size+60, \n",
    "#     repetition_penalty=20., \n",
    "#     temperature=20.,\n",
    "#     num_beams=30,\n",
    "# )\n",
    "\n",
    "# decoded = tokenizer.decode(output[0])\n",
    "# result = decoded[len(prefix):]\n",
    "# print(prefix + result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb7358",
   "metadata": {},
   "source": [
    "–ü–æ—á–µ–º—É-—Ç–æ –∏–º–µ–Ω–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Å—Ç–∏—à–∫–∏ —É –º–æ–¥–µ–ª–∏ –ø–ª–æ—Ö–æ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –Ω–æ —Å–ª–µ–¥—É—é—â–∏–π —Å—Ç–∏—à–æ–∫ –æ–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ç –≤—Å–µ –≤—Ä–µ–º—è –ø—Ä–æ –û–ª–µ–≥–∞, –∏ –∫–∞–∂–¥—ã–π —Ä–∞–∑ —Ç–∞–º —à–µ–¥–µ–≤—Ä)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
