{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28160934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pyconll\n",
    "import nltk\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c8c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a4cd6d",
   "metadata": {},
   "source": [
    "## task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc464492",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = pyconll.load_from_file('D:/GeekBrains/nlp/les05/data/ru_syntagrus-ud-train.conllu')\n",
    "full_test = pyconll.load_from_file('D:/GeekBrains/nlp/les05/data/ru_syntagrus-ud-dev.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de9701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata_train = []\n",
    "for sent in full_train[:]:\n",
    "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_sent_test = [] #только слова, без меток\n",
    "for sent in full_test[:]:\n",
    "    fdata_sent_test.append([token.form for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d213eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata_labels_test = [] \n",
    "for sent in full_test[:]:\n",
    "    fdata_labels_test.append([token.upos for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf594cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdata_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a193be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdata_train_all = [word for sent in fdata_train for word in sent]\n",
    "# fdata_test_all = [word for sent in fdata_test for word in sent]\n",
    "# fdata_sent_test_all = [word for sent in fdata_sent_test for word in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f049a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['NOUN', 'PUNCT', 'ADP', 'PART', 'PROPN', 'ADJ', 'VERB', 'CCONJ', 'ADV', 'PRON', 'SCONJ', 'DET', 'AUX', 'NUM', 'X', None, 'SYM', 'INTJ']),\n",
       " dict_values([27974, 22694, 10585, 3875, 4438, 11222, 13078, 4410, 6165, 5598, 2258, 3085, 1108, 1829, 105, 204, 53, 11]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "lbls = [lbl for sent in fdata_labels_test for lbl in sent]\n",
    "Counter(lbls).keys(), Counter(lbls).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe60eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['NOUN', 'PUNCT', 'ADP', 'PART', 'PROPN', 'ADJ', 'VERB', 'CCONJ', 'ADV', 'PRON', 'SCONJ', 'DET', 'AUX', 'NUM', 'X', None, 'SYM', 'INTJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c6271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317dfef",
   "metadata": {},
   "source": [
    "### nltk taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6831eeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"', 'PUNCT'),\n",
       " ('Алгоритм', None),\n",
       " ('-', 'PUNCT'),\n",
       " ('это', 'PRON'),\n",
       " ('всякая', 'DET'),\n",
       " ('система', 'NOUN'),\n",
       " ('вычислений', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('выполняемых', 'VERB'),\n",
       " ('по', 'ADP'),\n",
       " ('строго', 'ADV'),\n",
       " ('определённым', None),\n",
       " ('правилам', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('которая', 'PRON'),\n",
       " ('после', 'ADP'),\n",
       " ('какого-либо', 'DET'),\n",
       " ('числа', 'NOUN'),\n",
       " ('шагов', 'NOUN'),\n",
       " ('заведомо', 'ADV'),\n",
       " ('приводит', 'VERB'),\n",
       " ('к', 'ADP'),\n",
       " ('решению', 'NOUN'),\n",
       " ('поставленной', 'VERB'),\n",
       " ('задачи', 'NOUN'),\n",
       " ('\"', 'PUNCT'),\n",
       " ('.', 'PUNCT'),\n",
       " ('(', 'PUNCT'),\n",
       " ('А.', 'PROPN'),\n",
       " ('Колмогоров', 'PROPN'),\n",
       " (')', 'PUNCT'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8772537323492737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unigram_tagger = UnigramTagger(fdata_train)\n",
    "res['unigram'] = unigram_tagger.evaluate(fdata_test)\n",
    "display(unigram_tagger.tag(fdata_sent_test[10]), unigram_tagger.evaluate(fdata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6f3dbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"', 'PUNCT'),\n",
       " ('Алгоритм', None),\n",
       " ('-', 'PUNCT'),\n",
       " ('это', 'PRON'),\n",
       " ('всякая', 'DET'),\n",
       " ('система', 'NOUN'),\n",
       " ('вычислений', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('выполняемых', 'VERB'),\n",
       " ('по', 'ADP'),\n",
       " ('строго', 'ADV'),\n",
       " ('определённым', None),\n",
       " ('правилам', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('которая', 'PRON'),\n",
       " ('после', 'ADP'),\n",
       " ('какого-либо', 'DET'),\n",
       " ('числа', 'NOUN'),\n",
       " ('шагов', 'NOUN'),\n",
       " ('заведомо', 'ADV'),\n",
       " ('приводит', 'VERB'),\n",
       " ('к', 'ADP'),\n",
       " ('решению', 'NOUN'),\n",
       " ('поставленной', 'VERB'),\n",
       " ('задачи', 'NOUN'),\n",
       " ('\"', 'PUNCT'),\n",
       " ('.', 'PUNCT'),\n",
       " ('(', 'PUNCT'),\n",
       " ('А.', 'PROPN'),\n",
       " ('Колмогоров', 'PROPN'),\n",
       " (')', 'PUNCT'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8829828463586425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigram_tagger = BigramTagger(fdata_train, backoff=unigram_tagger)\n",
    "res['bigram'] =  bigram_tagger.evaluate(fdata_test)\n",
    "display(bigram_tagger.tag(fdata_sent_test[10]), bigram_tagger.evaluate(fdata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8918872f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"', 'PUNCT'),\n",
       " ('Алгоритм', None),\n",
       " ('-', 'PUNCT'),\n",
       " ('это', 'PRON'),\n",
       " ('всякая', 'DET'),\n",
       " ('система', 'NOUN'),\n",
       " ('вычислений', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('выполняемых', 'VERB'),\n",
       " ('по', 'ADP'),\n",
       " ('строго', 'ADV'),\n",
       " ('определённым', None),\n",
       " ('правилам', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('которая', 'PRON'),\n",
       " ('после', 'ADP'),\n",
       " ('какого-либо', 'DET'),\n",
       " ('числа', 'NOUN'),\n",
       " ('шагов', 'NOUN'),\n",
       " ('заведомо', 'ADV'),\n",
       " ('приводит', 'VERB'),\n",
       " ('к', 'ADP'),\n",
       " ('решению', 'NOUN'),\n",
       " ('поставленной', 'VERB'),\n",
       " ('задачи', 'NOUN'),\n",
       " ('\"', 'PUNCT'),\n",
       " ('.', 'PUNCT'),\n",
       " ('(', 'PUNCT'),\n",
       " ('А.', 'PROPN'),\n",
       " ('Колмогоров', 'PROPN'),\n",
       " (')', 'PUNCT'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.882081353418933"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trigram_tagger = TrigramTagger(fdata_train, backoff=bigram_tagger)\n",
    "res['trigram'] =  trigram_tagger.evaluate(fdata_test)\n",
    "display(trigram_tagger.tag(fdata_sent_test[10]), trigram_tagger.evaluate(fdata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4787ef06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882081353418933"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger.evaluate(fdata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5757fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9119991237825633"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
    "    for cls in tagger_classes:\n",
    "        backoff = cls(train_sents, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "\n",
    "backoff = DefaultTagger('NOUN') # самый популярный в test\n",
    "tag = backoff_tagger(fdata_train,  \n",
    "                     [UnigramTagger, BigramTagger, TrigramTagger],  \n",
    "                     backoff = backoff) \n",
    "\n",
    "res['combo'] =  tag.evaluate(fdata_test) \n",
    "tag.evaluate(fdata_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc15ceb1",
   "metadata": {},
   "source": [
    "### models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dbf0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = []\n",
    "train_label = []\n",
    "for sent in fdata_train[:]:\n",
    "    for tok in sent:\n",
    "        train_tok.append(tok[0])\n",
    "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
    "        \n",
    "test_tok = []\n",
    "test_label = []\n",
    "for sent in fdata_test[:]:\n",
    "    for tok in sent:\n",
    "        test_tok.append(tok[0])\n",
    "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0e64e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Начальник', 'NOUN'),\n",
       " ('областного', 'ADJ'),\n",
       " ('управления', 'NOUN'),\n",
       " ('связи', 'NOUN'),\n",
       " ('Семен', 'PROPN'),\n",
       " ('Еремеевич', 'PROPN'),\n",
       " ('был', 'AUX'),\n",
       " ('человек', 'NOUN'),\n",
       " ('простой', 'ADJ'),\n",
       " (',', 'PUNCT'),\n",
       " ('приходил', 'VERB'),\n",
       " ('на', 'ADP'),\n",
       " ('работу', 'NOUN'),\n",
       " ('всегда', 'ADV'),\n",
       " ('вовремя', 'ADV'),\n",
       " (',', 'PUNCT'),\n",
       " ('здоровался', 'VERB'),\n",
       " ('с', 'ADP'),\n",
       " ('секретаршей', 'NOUN'),\n",
       " ('за', 'ADP'),\n",
       " ('руку', 'NOUN'),\n",
       " ('и', 'CCONJ'),\n",
       " ('иногда', 'ADV'),\n",
       " ('даже', 'PART'),\n",
       " ('писал', 'VERB'),\n",
       " ('в', 'ADP'),\n",
       " ('стенгазету', 'NOUN'),\n",
       " ('заметки', 'NOUN'),\n",
       " ('под', 'ADP'),\n",
       " ('псевдонимом', 'NOUN'),\n",
       " ('\"', 'PUNCT'),\n",
       " ('Муха', 'NOUN'),\n",
       " ('\"', 'PUNCT'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdata_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1367cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tok[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24548b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(train_label)\n",
    "test_enc_labels = le.transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ee06cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword_ru = stopwords.words('russian')\n",
    "with open('stopwords.txt', encoding='utf8') as f:\n",
    "    additional_stopwords = set([w.strip() for w in f.readlines() if w]) # from https://github.com/stopwords-iso and others\n",
    "stopword_ru += list(additional_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda6436",
   "metadata": {},
   "source": [
    "#### tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "524522b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfvect = TfidfVectorizer(ngram_range=(1, 4), analyzer='char', binary=False, max_features = 1000, stop_words = stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed5b5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfvect.fit_transform(train_tok)\n",
    "X_test = tfvect.transform(test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "974f3528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8953257169817679"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, train_enc_labels)\n",
    "pred = lr.predict(X_test)\n",
    "res['tfvect'] =  accuracy_score(test_enc_labels, pred)\n",
    "accuracy_score(test_enc_labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f1a8e",
   "metadata": {},
   "source": [
    "#### hashing vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6687dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvect = HashingVectorizer(ngram_range=(1, 4), analyzer='char', binary=False, n_features = 1000, stop_words = stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06a5d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:502: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "X_train = hvect.fit_transform(train_tok)\n",
    "X_test = hvect.transform(test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3d2666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8866562194587673"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, train_enc_labels)\n",
    "pred = lr.predict(X_test)\n",
    "res['hvect'] =  accuracy_score(test_enc_labels, pred)\n",
    "accuracy_score(test_enc_labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2d065",
   "metadata": {},
   "source": [
    "#### count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9423d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(ngram_range=(1, 4), analyzer='char', binary=False, max_features = 1000, stop_words = stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bbea2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cvect.fit_transform(train_tok)\n",
    "X_test = cvect.transform(test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02305206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9010042799851717"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, train_enc_labels)\n",
    "pred = lr.predict(X_test)\n",
    "res['cvect'] =  accuracy_score(test_enc_labels, pred)\n",
    "accuracy_score(test_enc_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25702815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "CM = confusion_matrix(test_enc_labels, pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=CM)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(CM, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xlabel('предсказаны')\n",
    "plt.ylabel('истина')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e978491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN',\n",
       "       'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
       "       'VERB', 'X'], dtype='<U6')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(list(np.arange(18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ebfb3",
   "metadata": {},
   "source": [
    "Точнее всего предсказываются 7 и 13 классы - 'NOUN' и 'PUNCT', хуже всего 6, 8, 15, 17 - 'INTJ', 'NO_TAG', 'SYM', 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa061d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9894,     5,   284,     1,     1,    22,     0,   577,     0,\n",
       "           14,     3,     9,   121,    11,     2,     0,   278,     0],\n",
       "       [    0, 10481,    11,     0,     0,     0,     0,    89,     0,\n",
       "            0,     0,     1,     1,     0,     0,     0,     2,     0],\n",
       "       [  197,    45,  5250,     0,     6,    25,     0,   311,     0,\n",
       "           22,     6,    23,    24,     0,   175,     0,    81,     0],\n",
       "       [    0,     3,     0,  1074,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,    31,     0],\n",
       "       [    0,     0,     3,     0,  4403,     0,     0,     0,     0,\n",
       "            0,     4,     0,     0,     0,     0,     0,     0,     0],\n",
       "       [    4,     6,     4,     0,     0,  2440,     0,    15,     0,\n",
       "           70,     5,   499,     4,     0,    38,     0,     0,     0],\n",
       "       [    0,     1,     0,     0,     0,     1,     0,     9,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       [  408,    83,   209,     3,    17,    26,     0, 25856,     0,\n",
       "           38,    35,    66,   646,     2,     3,     0,   582,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,   204,     0,     0,     0,     0],\n",
       "       [    3,    14,    31,     0,     0,     3,     0,    28,     0,\n",
       "         1575,     0,     6,     0,   161,     0,     0,     8,     0],\n",
       "       [    0,     1,    39,    50,   621,    78,     0,     9,     0,\n",
       "            0,  2958,    20,    11,     0,    57,     0,    31,     0],\n",
       "       [    3,     0,    16,     0,     5,   405,     0,    11,     0,\n",
       "            0,     5,  4707,     0,     0,   446,     0,     0,     0],\n",
       "       [  225,    46,    57,     2,     9,     6,     0,  1780,     0,\n",
       "           12,     4,    11,  1631,   346,     1,     0,   308,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0, 22694,     0,     0,     0,     0],\n",
       "       [    0,     0,    23,     0,    12,     0,     0,     4,     0,\n",
       "            1,    14,    13,     1,     0,  2190,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,    53,     0,     0,     0,     0],\n",
       "       [  300,    13,    70,   192,     4,     7,     0,   648,     0,\n",
       "            0,     2,     1,    52,     0,     0,     0, 11789,     0],\n",
       "       [    0,     1,     1,     0,     0,     0,     0,    10,     0,\n",
       "            0,     0,     0,     3,    90,     0,     0,     0,     0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32ae8a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect_w = CountVectorizer(ngram_range=(1, 4), analyzer='word', binary=False, max_features = 1000, stop_words = stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35338a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "X_train = cvect_w.fit_transform(train_tok)\n",
    "X_test = cvect_w.transform(test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa557c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2820156371111785"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, train_enc_labels)\n",
    "pred = lr.predict(X_test)\n",
    "res['cvect_word'] =  accuracy_score(test_enc_labels, pred)\n",
    "accuracy_score(test_enc_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02607e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>combo</th>\n",
       "      <td>0.911999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cvect</th>\n",
       "      <td>0.901004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfvect</th>\n",
       "      <td>0.895326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hvect</th>\n",
       "      <td>0.886656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigram</th>\n",
       "      <td>0.882983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trigram</th>\n",
       "      <td>0.882081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unigram</th>\n",
       "      <td>0.877254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cvect_word</th>\n",
       "      <td>0.282016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy\n",
       "combo       0.911999\n",
       "cvect       0.901004\n",
       "tfvect      0.895326\n",
       "hvect       0.886656\n",
       "bigram      0.882983\n",
       "trigram     0.882081\n",
       "unigram     0.877254\n",
       "cvect_word  0.282016"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(res, orient='index', columns = ['accuracy']).sort_values(by = 'accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57e743",
   "metadata": {},
   "source": [
    "Count vectorizer работает почти так же хорошо, как и комбинация тэггеров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb2d27",
   "metadata": {},
   "source": [
    "## task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81e008cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ne5Markup(\n",
       "    id='001',\n",
       "    text='юя\\x04 \\x04>\\x04A\\x04A\\x048\\x04O\\x00 \\x04@\\x040\\x04A\\x04A\\x04G\\x048\\x04B\\x04K\\x042\\x040\\x045\\x04B\\x00 \\x04=\\x040\\x00 \\x04:\\x04>\\x04=\\x04A\\x04B\\x04@\\x04C\\x04:\\x04B\\x048\\x042\\x04=\\x04>\\x045\\x00 \\x042\\x04>\\x047\\x044\\x045\\x049\\x04A\\x04B\\x042\\x048\\x045\\x00 \\x04!\\x04(\\x04\\x10\\x00 \\x04=\\x040\\x00 \\x04\\x13\\x04@\\x04C\\x047\\x048\\x04N\\x00\\r\\x00\\n\\x00\\r\\x00\\n\\x000\\x004\\x00/\\x000\\x008\\x00/\\x002\\x000\\x000\\x008\\x00 \\x001\\x002\\x00:\\x000\\x008\\x00\\r\\x00\\n\\x00\\r\\x00\\n\\x04\\x1c\\x04\\x1e\\x04!\\x04\\x1a\\x04\\x12\\x04\\x10\\x00,\\x00 \\x004\\x00 \\x040\\x042\\x043\\x00 \\x00-\\x00 \\x04 \\x04\\x18\\x04\\x10\\x00 \\x04\\x1d\\x04>\\x042\\x04>\\x04A\\x04B\\x048\\x00.\\x00 \\x04 \\x04>\\x04A\\x04A\\x048\\x04O\\x00 \\x04@\\x040\\x04A\\x04A\\x04G\\x048\\x04B\\x04K\\x042\\x040\\x045\\x04B\\x00,\\x00 \\x04G\\x04B\\x04>\\x00 \\x04!\\x04(\\x04\\x10\\x00 \\x042\\x04>\\x047\\x044\\x045\\x049\\x04A\\x04B\\x042\\x04C\\x04N\\x04B\\x00 \\x04=\\x040\\x00 \\x04\"\\x041\\x048\\x04;\\x048\\x04A\\x048\\x00 \\x042\\x00 \\x04A\\x042\\x04O\\x047\\x048\\x00 \\x04A\\x00 \\x04>\\x041\\x04>\\x04A\\x04B\\x04@\\x045\\x04=\\x048\\x045\\x04<\\x00 \\x04A\\x048\\x04B\\x04C\\x040\\x04F\\x048\\x048\\x00 \\x042\\x00 \\x047\\x04>\\x04=\\x045\\x00 \\x043\\x04@\\x04C\\x047\\x048\\x04=\\x04>\\x00-\\x04>\\x04A\\x045\\x04B\\x048\\x04=\\x04A\\x04:\\x04>\\x043\\x04>\\x00 \\x04:\\x04>\\x04=\\x04D\\x04;\\x048\\x04:\\x04B\\x040\\x00.\\x00 \\x04\\x1e\\x041\\x00 \\x04M\\x04B\\x04>\\x04<\\x00 \\x04A\\x04B\\x040\\x04B\\x04A\\x00-\\x04A\\x045\\x04:\\x04@\\x045\\x04B\\x040\\x04@\\x04L\\x00 \\x00-\\x00 \\x047\\x040\\x04<\\x045\\x04A\\x04B\\x048\\x04B\\x045\\x04;\\x04L\\x00 \\x04<\\x048\\x04=\\x048\\x04A\\x04B\\x04@\\x040\\x00 \\x048\\x04=\\x04>\\x04A\\x04B\\x04@\\x040\\x04=\\x04=\\x04K\\x04E\\x00 \\x044\\x045\\x04;\\x00 \\x04 \\x04>\\x04A\\x04A\\x048\\x048\\x00 \\x04\\x13\\x04@\\x048\\x043\\x04>\\x04@\\x048\\x049\\x00 \\x04\\x1a\\x040\\x04@\\x040\\x04A\\x048\\x04=\\x00 \\x047\\x040\\x04O\\x042\\x048\\x04;\\x00 \\x042\\x00 \\x04B\\x045\\x04;\\x045\\x04D\\x04>\\x04=\\x04=\\x04>\\x04<\\x00 \\x04@\\x040\\x047\\x043\\x04>\\x042\\x04>\\x04@\\x045\\x00 \\x04A\\x00 \\x047\\x040\\x04<\\x045\\x04A\\x04B\\x048\\x04B\\x045\\x04;\\x045\\x04<\\x00 \\x043\\x04>\\x04A\\x04A\\x045\\x04:\\x04@\\x045\\x04B\\x040\\x04@\\x04O\\x00 \\x04!\\x04(\\x04\\x10\\x00 \\x04\\x14\\x04M\\x04=\\x048\\x04M\\x04;\\x04>\\x04<\\x00 \\x04$\\x04@\\x048\\x044\\x04>\\x04<\\x00.\\x00\\r\\x00\\n\\x00\\r\\x00\\n\\x00\"\\x04!\\x00 \\x04@\\x04>\\x04A\\x04A\\x048\\x049\\x04A\\x04:\\x04>\\x049\\x00 \\x04A\\x04B\\x04>\\x04@\\x04>\\x04=\\x04K\\x00 \\x042\\x04K\\x04@\\x040\\x046\\x045\\x04=\\x040\\x00 \\x043\\x04;\\x04C\\x041\\x04>\\x04:\\x040\\x04O\\x00 \\x04>\\x047\\x040\\x041\\x04>\\x04G\\x045\\x04=\\x04=\\x04>\\x04A\\x04B\\x04L\\x00 \\x042\\x00 \\x04A\\x042\\x04O\\x047\\x048\\x00 \\x04A\\x00 \\x04=\\x04>\\x042\\x04K\\x04<\\x00 \\x042\\x048\\x04B\\x04:\\x04>\\x04<\\x00 \\x04=\\x040\\x04?\\x04@\\x04O\\x046\\x045\\x04=\\x04=\\x04>\\x04A\\x04B\\x048\\x00 \\x042\\x04>\\x04:\\x04@\\x04C\\x043\\x00 \\x04.\\x046\\x04=\\x04>\\x049\\x00 \\x04\\x1e\\x04A\\x045\\x04B\\x048\\x048\\x00,\\x00 \\x04?\\x04@\\x04>\\x04B\\x048\\x042\\x04>\\x047\\x040\\x04:\\x04>\\x04=\\x04=\\x04K\\x04<\\x048\\x00 \\x044\\x045\\x049\\x04A\\x04B\\x042\\x048\\x04O\\x04<\\x048\\x00 \\x043\\x04@\\x04C\\x047\\x048\\x04=\\x04A\\x04:\\x04>\\x049\\x00 \\x04A\\x04B\\x04>\\x04@\\x04>\\x04=\\x04K\\x00 \\x04?\\x04>\\x00 \\x04=\\x040\\x04@\\x040\\x04I\\x048\\x042\\x040\\x04=\\x048\\x04N\\x00 \\x04A\\x042\\x04>\\x048\\x04E\\x00 \\x042\\x04>\\x04>\\x04@\\x04C\\x046\\x045\\x04=\\x04=\\x04K\\x04E\\x00 \\x04A\\x048\\x04;\\x00 \\x042\\x00 \\x04@\\x045\\x043\\x048\\x04>\\x04=\\x045\\x00,\\x00 \\x041\\x045\\x04A\\x04:\\x04>\\x04=\\x04B\\x04@\\x04>\\x04;\\x04L\\x04=\\x04K\\x04<\\x00 \\x04A\\x04B\\x04@\\x04>\\x048\\x04B\\x045\\x04;\\x04L\\x04A\\x04B\\x042\\x04>\\x04<\\x00 \\x04D\\x04>\\x04@\\x04B\\x048\\x04D\\x048\\x04:\\x040\\x04F\\x048\\x04>\\x04=\\x04=\\x04K\\x04E\\x00 \\x04A\\x04>\\x04>\\x04@\\x04C\\x046\\x045\\x04=\\x048\\x049\\x00\"\\x00,\\x00 \\x00-\\x00 \\x043\\x04>\\x042\\x04>\\x04@\\x048\\x04B\\x04A\\x04O\\x00 \\x042\\x00 \\x04A\\x04>\\x04>\\x041\\x04I\\x045\\x04=\\x048\\x048\\x00.\\x00\\r\\x00\\n\\x00\\r\\x00\\n\\x00\"\\x04 \\x04>\\x04A\\x04A\\x048\\x04O\\x00 \\x04C\\x046\\x045\\x00 \\x04?\\x04@\\x048\\x047\\x042\\x040\\x04;\\x040\\x00 \\x04\"\\x041\\x048\\x04;\\x048\\x04A\\x048\\x00 \\x04:\\x00 \\x04>\\x04B\\x042\\x045\\x04B\\x04A\\x04B\\x042\\x045\\x04=\\x04=\\x04>\\x049\\x00 \\x04;\\x048\\x04=\\x048\\x048\\x00 \\x048\\x00 \\x04@\\x040\\x04A\\x04A\\x04G\\x048\\x04B\\x04K\\x042\\x040\\x045\\x04B\\x00 \\x04B\\x040\\x04:\\x046\\x045\\x00 \\x04=\\x040\\x00 \\x04:\\x04>\\x04=\\x04A\\x04B\\x04@\\x04C\\x04:\\x04B\\x048\\x042\\x04=\\x04>\\x045\\x00 \\x042\\x04>\\x047\\x044\\x045\\x049\\x04A\\x04B\\x042\\x048\\x045\\x00 \\x04A\\x04>\\x00 \\x04A\\x04B\\x04>\\x04@\\x04>\\x04=\\x04K\\x00 \\x04\\x12\\x040\\x04H\\x048\\x04=\\x043\\x04B\\x04>\\x04=\\x040\\x00\"\\x00,\\x00 \\x00-\\x00 \\x04A\\x04>\\x04>\\x041\\x04I\\x048\\x04;\\x00 \\x04\\x1c\\x04\\x18\\x04\\x14\\x00 \\x04 \\x04>\\x04A\\x04A\\x048\\x048\\x00.\\x00 ',\n",
       "    spans=[Ne5Span(\n",
       "         index='T1',\n",
       "         type='GEOPOLIT',\n",
       "         start=0,\n",
       "         stop=6,\n",
       "         text='Россия'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T2',\n",
       "         type='GEOPOLIT',\n",
       "         start=50,\n",
       "         stop=53,\n",
       "         text='США'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T3',\n",
       "         type='GEOPOLIT',\n",
       "         start=57,\n",
       "         stop=63,\n",
       "         text='Грузию'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T4',\n",
       "         type='LOC',\n",
       "         start=87,\n",
       "         stop=93,\n",
       "         text='МОСКВА'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T5',\n",
       "         type='MEDIA',\n",
       "         start=103,\n",
       "         stop=114,\n",
       "         text='РИА Новости'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T6',\n",
       "         type='GEOPOLIT',\n",
       "         start=116,\n",
       "         stop=122,\n",
       "         text='Россия'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T7',\n",
       "         type='GEOPOLIT',\n",
       "         start=141,\n",
       "         stop=144,\n",
       "         text='США'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T8',\n",
       "         type='GEOPOLIT',\n",
       "         start=161,\n",
       "         stop=168,\n",
       "         text='Тбилиси'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T9',\n",
       "         type='GEOPOLIT',\n",
       "         start=301,\n",
       "         stop=307,\n",
       "         text='России'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T10',\n",
       "         type='PER',\n",
       "         start=308,\n",
       "         stop=324,\n",
       "         text='Григорий Карасин'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T11',\n",
       "         type='GEOPOLIT',\n",
       "         start=383,\n",
       "         stop=386,\n",
       "         text='США'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T12',\n",
       "         type='PER',\n",
       "         start=387,\n",
       "         stop=402,\n",
       "         text='Дэниэлом Фридом'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T13',\n",
       "         type='GEOPOLIT',\n",
       "         start=505,\n",
       "         stop=517,\n",
       "         text='Южной Осетии'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T14',\n",
       "         type='GEOPOLIT',\n",
       "         start=703,\n",
       "         stop=709,\n",
       "         text='Россия'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T15',\n",
       "         type='GEOPOLIT',\n",
       "         start=723,\n",
       "         stop=730,\n",
       "         text='Тбилиси'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T16',\n",
       "         type='GEOPOLIT',\n",
       "         start=815,\n",
       "         stop=825,\n",
       "         text='Вашингтона'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T17',\n",
       "         type='ORG',\n",
       "         start=838,\n",
       "         stop=841,\n",
       "         text='МИД'\n",
       "     ),\n",
       "     Ne5Span(\n",
       "         index='T18',\n",
       "         type='GEOPOLIT',\n",
       "         start=842,\n",
       "         stop=848,\n",
       "         text='России'\n",
       "     )]\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import corus\n",
    "from corus import load_ne5\n",
    "\n",
    "dir = 'D:/GeekBrains/nlp/les05/data/Collection5_n/'\n",
    "records = load_ne5(dir)\n",
    "next(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e3a3268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\n",
    "data = pd.read_csv('D:/GeekBrains/nlp/les05/data/ner_dataset.csv', encoding= 'unicode_escape')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46f32089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentence #']=data['Sentence #'].ffill(axis = 0) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cf7059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищенный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•`'·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", '', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', '', text.strip())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "400fd9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Possible nested set at position 41\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data['Word'] = data['Word'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1b22a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Word'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8f9a876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 948403 entries, 0 to 1048574\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Sentence #  948403 non-null  object\n",
      " 1   Word        948403 non-null  object\n",
      " 2   POS         948403 non-null  object\n",
      " 3   Tag         948403 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 36.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e6cfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w,p, t) for w,p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                        s[\"Tag\"].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f5a096c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence_POS_Tag_Pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[(Thousands, NNS, O), (of, IN, O), (demonstrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[(Iranian, JJ, B-gpe), (officials, NNS, O), (s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[(Helicopter, NN, O), (gunships, NNS, O), (Sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[(They, PRP, O), (left, VBD, O), (after, IN, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[(UN, NNP, B-geo), (relief, NN, O), (coordinat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                              Sentence_POS_Tag_Pair\n",
       "0      Sentence: 1  [(Thousands, NNS, O), (of, IN, O), (demonstrat...\n",
       "1     Sentence: 10  [(Iranian, JJ, B-gpe), (officials, NNS, O), (s...\n",
       "2    Sentence: 100  [(Helicopter, NN, O), (gunships, NNS, O), (Sat...\n",
       "3   Sentence: 1000  [(They, PRP, O), (left, VBD, O), (after, IN, O...\n",
       "4  Sentence: 10000  [(UN, NNP, B-geo), (relief, NN, O), (coordinat..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data=data.groupby(['Sentence #']).apply(agg_func).reset_index().rename(columns={0:'Sentence_POS_Tag_Pair'})\n",
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1324a35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence_POS_Tag_Pair</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[(Thousands, NNS, O), (of, IN, O), (demonstrat...</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...</td>\n",
       "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[(Iranian, JJ, B-gpe), (officials, NNS, O), (s...</td>\n",
       "      <td>Iranian officials say they expect to get acces...</td>\n",
       "      <td>JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...</td>\n",
       "      <td>B-gpe O O O O O O O O O O O O O O B-tim O O B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[(Helicopter, NN, O), (gunships, NNS, O), (Sat...</td>\n",
       "      <td>Helicopter gunships Saturday pounded militant ...</td>\n",
       "      <td>NN NNS NNP VBD JJ NNS IN DT NNP JJ NN WRB JJ N...</td>\n",
       "      <td>O O B-tim O O O O O B-geo O O O O B-org O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[(They, PRP, O), (left, VBD, O), (after, IN, O...</td>\n",
       "      <td>They left after a tense hourlong standoff with...</td>\n",
       "      <td>PRP VBD IN DT NN JJ NN IN NN NNS</td>\n",
       "      <td>O O O O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[(UN, NNP, B-geo), (relief, NN, O), (coordinat...</td>\n",
       "      <td>UN relief coordinator Jan Egeland said Sunday ...</td>\n",
       "      <td>NNP NN NN NNP NNP VBD NNP NNP JJ CC JJ JJ NNS ...</td>\n",
       "      <td>B-geo O O B-per I-per O B-tim B-geo B-gpe O B-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                              Sentence_POS_Tag_Pair  \\\n",
       "0      Sentence: 1  [(Thousands, NNS, O), (of, IN, O), (demonstrat...   \n",
       "1     Sentence: 10  [(Iranian, JJ, B-gpe), (officials, NNS, O), (s...   \n",
       "2    Sentence: 100  [(Helicopter, NN, O), (gunships, NNS, O), (Sat...   \n",
       "3   Sentence: 1000  [(They, PRP, O), (left, VBD, O), (after, IN, O...   \n",
       "4  Sentence: 10000  [(UN, NNP, B-geo), (relief, NN, O), (coordinat...   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Iranian officials say they expect to get acces...   \n",
       "2  Helicopter gunships Saturday pounded militant ...   \n",
       "3  They left after a tense hourlong standoff with...   \n",
       "4  UN relief coordinator Jan Egeland said Sunday ...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...   \n",
       "1  JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...   \n",
       "2  NN NNS NNP VBD JJ NNS IN DT NNP JJ NN WRB JJ N...   \n",
       "3                   PRP VBD IN DT NN JJ NN IN NN NNS   \n",
       "4  NNP NN NN NNP NNP VBD NNP NNP JJ CC JJ JJ NNS ...   \n",
       "\n",
       "                                                 Tag  \n",
       "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...  \n",
       "1  B-gpe O O O O O O O O O O O O O O B-tim O O B-...  \n",
       "2  O O B-tim O O O O O B-geo O O O O B-org O O O ...  \n",
       "3                                O O O O O O O O O O  \n",
       "4  B-geo O O B-per I-per O B-tim B-geo B-gpe O B-...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data['Sentence']=agg_data['Sentence_POS_Tag_Pair'].apply(lambda sentence:\" \".join([s[0] for s in sentence]))\n",
    "agg_data['POS']=agg_data['Sentence_POS_Tag_Pair'].apply(lambda sentence:\" \".join([s[1] for s in sentence]))\n",
    "agg_data['Tag']=agg_data['Sentence_POS_Tag_Pair'].apply(lambda sentence:\" \".join([s[2] for s in sentence]))\n",
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42374332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence_POS_Tag_Pair</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>tag_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[(Thousands, NNS, O), (of, IN, O), (demonstrat...</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...</td>\n",
       "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[(Iranian, JJ, B-gpe), (officials, NNS, O), (s...</td>\n",
       "      <td>Iranian officials say they expect to get acces...</td>\n",
       "      <td>JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...</td>\n",
       "      <td>B-gpe O O O O O O O O O O O O O O B-tim O O B-...</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[(Helicopter, NN, O), (gunships, NNS, O), (Sat...</td>\n",
       "      <td>Helicopter gunships Saturday pounded militant ...</td>\n",
       "      <td>NN NNS NNP VBD JJ NNS IN DT NNP JJ NN WRB JJ N...</td>\n",
       "      <td>O O B-tim O O O O O B-geo O O O O B-org O O O ...</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[(They, PRP, O), (left, VBD, O), (after, IN, O...</td>\n",
       "      <td>They left after a tense hourlong standoff with...</td>\n",
       "      <td>PRP VBD IN DT NN JJ NN IN NN NNS</td>\n",
       "      <td>O O O O O O O O O O</td>\n",
       "      <td>[They, left, after, a, tense, hourlong, stando...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[(UN, NNP, B-geo), (relief, NN, O), (coordinat...</td>\n",
       "      <td>UN relief coordinator Jan Egeland said Sunday ...</td>\n",
       "      <td>NNP NN NN NNP NNP VBD NNP NNP JJ CC JJ JJ NNS ...</td>\n",
       "      <td>B-geo O O B-per I-per O B-tim B-geo B-gpe O B-...</td>\n",
       "      <td>[UN, relief, coordinator, Jan, Egeland, said, ...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, B-geo, B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                              Sentence_POS_Tag_Pair  \\\n",
       "0      Sentence: 1  [(Thousands, NNS, O), (of, IN, O), (demonstrat...   \n",
       "1     Sentence: 10  [(Iranian, JJ, B-gpe), (officials, NNS, O), (s...   \n",
       "2    Sentence: 100  [(Helicopter, NN, O), (gunships, NNS, O), (Sat...   \n",
       "3   Sentence: 1000  [(They, PRP, O), (left, VBD, O), (after, IN, O...   \n",
       "4  Sentence: 10000  [(UN, NNP, B-geo), (relief, NN, O), (coordinat...   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Iranian officials say they expect to get acces...   \n",
       "2  Helicopter gunships Saturday pounded militant ...   \n",
       "3  They left after a tense hourlong standoff with...   \n",
       "4  UN relief coordinator Jan Egeland said Sunday ...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...   \n",
       "1  JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...   \n",
       "2  NN NNS NNP VBD JJ NNS IN DT NNP JJ NN WRB JJ N...   \n",
       "3                   PRP VBD IN DT NN JJ NN IN NN NNS   \n",
       "4  NNP NN NN NNP NNP VBD NNP NNP JJ CC JJ JJ NNS ...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...   \n",
       "1  B-gpe O O O O O O O O O O O O O O B-tim O O B-...   \n",
       "2  O O B-tim O O O O O B-geo O O O O B-org O O O ...   \n",
       "3                                O O O O O O O O O O   \n",
       "4  B-geo O O B-per I-per O B-tim B-geo B-gpe O B-...   \n",
       "\n",
       "                                 tokenised_sentences  \\\n",
       "0  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1  [Iranian, officials, say, they, expect, to, ge...   \n",
       "2  [Helicopter, gunships, Saturday, pounded, mili...   \n",
       "3  [They, left, after, a, tense, hourlong, stando...   \n",
       "4  [UN, relief, coordinator, Jan, Egeland, said, ...   \n",
       "\n",
       "                                            tag_list  \n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...  \n",
       "1  [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "2  [O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...  \n",
       "3                     [O, O, O, O, O, O, O, O, O, O]  \n",
       "4  [B-geo, O, O, B-per, I-per, O, B-tim, B-geo, B...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data['tokenised_sentences']=agg_data['Sentence'].apply(lambda x:x.split())\n",
    "agg_data['tag_list']=agg_data['Tag'].apply(lambda x:x.split())\n",
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae6859",
   "metadata": {},
   "source": [
    "#### nltk pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05957bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence_POS_Tag_Pair</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>tokenised_sentences</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>NLTK_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[(Thousands, NNS, O), (of, IN, O), (demonstrat...</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...</td>\n",
       "      <td>O O O O O O B-geo O O O O O B-geo O O O O O B-...</td>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "      <td>[(Thousands, NNS), (of, IN), (demonstrators, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[(Iranian, JJ, B-gpe), (officials, NNS, O), (s...</td>\n",
       "      <td>Iranian officials say they expect to get acces...</td>\n",
       "      <td>JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...</td>\n",
       "      <td>B-gpe O O O O O O O O O O O O O O B-tim O O B-...</td>\n",
       "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
       "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[(Iranian, JJ), (officials, NNS), (say, VBP), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[(Helicopter, NN, O), (gunships, NNS, O), (Sat...</td>\n",
       "      <td>Helicopter gunships Saturday pounded militant ...</td>\n",
       "      <td>NN NNS NNP VBD JJ NNS IN DT NNP JJ NN WRB JJ N...</td>\n",
       "      <td>O O B-tim O O O O O B-geo O O O O B-org O O O ...</td>\n",
       "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
       "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
       "      <td>[(Helicopter, NNP), (gunships, NNS), (Saturday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[(They, PRP, O), (left, VBD, O), (after, IN, O...</td>\n",
       "      <td>They left after a tense hourlong standoff with...</td>\n",
       "      <td>PRP VBD IN DT NN JJ NN IN NN NNS</td>\n",
       "      <td>O O O O O O O O O O</td>\n",
       "      <td>[They, left, after, a, tense, hourlong, stando...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[(They, PRP), (left, VBD), (after, IN), (a, DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[(UN, NNP, B-geo), (relief, NN, O), (coordinat...</td>\n",
       "      <td>UN relief coordinator Jan Egeland said Sunday ...</td>\n",
       "      <td>NNP NN NN NNP NNP VBD NNP NNP JJ CC JJ JJ NNS ...</td>\n",
       "      <td>B-geo O O B-per I-per O B-tim B-geo B-gpe O B-...</td>\n",
       "      <td>[UN, relief, coordinator, Jan, Egeland, said, ...</td>\n",
       "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, B-geo, B...</td>\n",
       "      <td>[(UN, NNP), (relief, NN), (coordinator, NN), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #                              Sentence_POS_Tag_Pair  \\\n",
       "0      Sentence: 1  [(Thousands, NNS, O), (of, IN, O), (demonstrat...   \n",
       "1     Sentence: 10  [(Iranian, JJ, B-gpe), (officials, NNS, O), (s...   \n",
       "2    Sentence: 100  [(Helicopter, NN, O), (gunships, NNS, O), (Sat...   \n",
       "3   Sentence: 1000  [(They, PRP, O), (left, VBD, O), (after, IN, O...   \n",
       "4  Sentence: 10000  [(UN, NNP, B-geo), (relief, NN, O), (coordinat...   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  Thousands of demonstrators have marched throug...   \n",
       "1  Iranian officials say they expect to get acces...   \n",
       "2  Helicopter gunships Saturday pounded militant ...   \n",
       "3  They left after a tense hourlong standoff with...   \n",
       "4  UN relief coordinator Jan Egeland said Sunday ...   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  NNS IN NNS VBP VBN IN NNP TO VB DT NN IN NNP C...   \n",
       "1  JJ NNS VBP PRP VBP TO VB NN TO JJ JJ NNS IN DT...   \n",
       "2  NN NNS NNP VBD JJ NNS IN DT NNP JJ NN WRB JJ N...   \n",
       "3                   PRP VBD IN DT NN JJ NN IN NN NNS   \n",
       "4  NNP NN NN NNP NNP VBD NNP NNP JJ CC JJ JJ NNS ...   \n",
       "\n",
       "                                                 Tag  \\\n",
       "0  O O O O O O B-geo O O O O O B-geo O O O O O B-...   \n",
       "1  B-gpe O O O O O O O O O O O O O O B-tim O O B-...   \n",
       "2  O O B-tim O O O O O B-geo O O O O B-org O O O ...   \n",
       "3                                O O O O O O O O O O   \n",
       "4  B-geo O O B-per I-per O B-tim B-geo B-gpe O B-...   \n",
       "\n",
       "                                 tokenised_sentences  \\\n",
       "0  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1  [Iranian, officials, say, they, expect, to, ge...   \n",
       "2  [Helicopter, gunships, Saturday, pounded, mili...   \n",
       "3  [They, left, after, a, tense, hourlong, stando...   \n",
       "4  [UN, relief, coordinator, Jan, Egeland, said, ...   \n",
       "\n",
       "                                            tag_list  \\\n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...   \n",
       "1  [B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
       "2  [O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...   \n",
       "3                     [O, O, O, O, O, O, O, O, O, O]   \n",
       "4  [B-geo, O, O, B-per, I-per, O, B-tim, B-geo, B...   \n",
       "\n",
       "                                         NLTK_labels  \n",
       "0  [(Thousands, NNS), (of, IN), (demonstrators, N...  \n",
       "1  [(Iranian, JJ), (officials, NNS), (say, VBP), ...  \n",
       "2  [(Helicopter, NNP), (gunships, NNS), (Saturday...  \n",
       "3  [(They, PRP), (left, VBD), (after, IN), (a, DT...  \n",
       "4  [(UN, NNP), (relief, NN), (coordinator, NN), (...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data['NLTK_labels'] = agg_data['Sentence'].apply(lambda x: nltk.pos_tag(nltk.word_tokenize(x)))\n",
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e52b786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels  = [token[1] for sent in agg_data['Sentence_POS_Tag_Pair'].values for token in sent]\n",
    "pred_labels  = [token[1] for sent in agg_data['NLTK_labels'].values for token in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2acb6ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(948403, 948403)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels), len(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf8387db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9426488528610728"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a129eecb",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52b25756",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_list = agg_data['Sentence'].tolist()\n",
    "tags_list = agg_data['tag_list'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dffafe9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country',\n",
       " ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-geo',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-geo',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-gpe',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_list[0], tags_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0e50d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = tf.keras.preprocessing.text.Tokenizer(lower=False,filters='')\n",
    "tokeniser.fit_on_texts(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2d34dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1078,\n",
       " 2,\n",
       " 1123,\n",
       " 14,\n",
       " 1789,\n",
       " 223,\n",
       " 468,\n",
       " 4,\n",
       " 519,\n",
       " 1,\n",
       " 151,\n",
       " 3,\n",
       " 56,\n",
       " 6,\n",
       " 567,\n",
       " 1,\n",
       " 812,\n",
       " 2,\n",
       " 173,\n",
       " 85,\n",
       " 19,\n",
       " 13,\n",
       " 50]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentence = tokeniser.texts_to_sequences(sentences_list)\n",
    "encoded_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "778ffd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeniser.index_word[1078]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a8abbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(data['Tag'].values))\n",
    "num_tags = len(tags)\n",
    "num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e1ce04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_map = {tag: i for i,tag in enumerate(tags)}\n",
    "# reverse_tag_map = {v: k for k, v in tags_map.items()}\n",
    "# tags_map, reverse_tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e992743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 10,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 10,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 8,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tags = [[tags_map[w] for w in tag] for tag in tags_list]\n",
    "encoded_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d12e4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentence_length = max([len(s.split()) for s in sentences_list])\n",
    "max_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5b49a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "padded_encoded_sentences = pad_sequences(maxlen = max_len, sequences = encoded_sentence, padding = \"post\", value = 0)\n",
    "padded_encoded_tags = pad_sequences(maxlen = max_len, sequences = encoded_tags, padding = \"post\", value=tags_map['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47da936d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1078,    2, 1123,   14, 1789,  223,  468,    4,  519,    1,  151,\n",
       "           3,   56,    6,  567,    1,  812,    2,  173,   85,   19,   13,\n",
       "          50,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0]),\n",
       " array([14, 14, 14, 14, 14, 14, 10, 14, 14, 14, 14, 14, 10, 14, 14, 14, 14,\n",
       "        14,  8, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_encoded_sentences[0], padded_encoded_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33448a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.]], dtype=float32),\n",
       " (128, 17))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [to_categorical(i, num_classes = num_tags) for i in padded_encoded_tags]\n",
    "target[0], target[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54698191",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_test, y_train, y_val_test = train_test_split(padded_encoded_sentences, target, test_size = 0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "904ec1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33570, 33570)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "034e4af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         4205440   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 17)          2193      \n",
      "=================================================================\n",
      "Total params: 4,339,217\n",
      "Trainable params: 4,339,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "vocab_size = len(tokeniser.word_index)+1\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, name = \"embedding\"),\n",
    "    LSTM(units = embedding_dim, return_sequences=True),\n",
    "    Dense(num_tags, activation = 'softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7fecc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edb671a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050/1050 [==============================] - 127s 120ms/step - loss: 0.2462 - accuracy: 0.9656 - val_loss: 0.0345 - val_accuracy: 0.9914\n",
      "Epoch 2/5\n",
      "1050/1050 [==============================] - 133s 127ms/step - loss: 0.0271 - accuracy: 0.9928 - val_loss: 0.0239 - val_accuracy: 0.9931\n",
      "Epoch 3/5\n",
      "1050/1050 [==============================] - 130s 124ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0225 - val_accuracy: 0.9932\n",
      "Epoch 4/5\n",
      "1050/1050 [==============================] - 133s 127ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0223 - val_accuracy: 0.9933\n",
      "Epoch 5/5\n",
      "1050/1050 [==============================] - 132s 126ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0221 - val_accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x199a6c9d908>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, np.array(y_train), validation_data = (X_val, np.array(y_val)), batch_size = 32, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73db4864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 4s 29ms/step - loss: 0.0223 - accuracy: 0.9934 0s - loss: 0.0223 - accuracy: 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9933927655220032"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, np.array(y_test), batch_size = 32)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd63f9",
   "metadata": {},
   "source": [
    "Результат получили выше, чем с nltk pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88d248fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = np.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1619c939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 13,  4, ..., 19, 14, 13],\n",
       "       [ 5,  5,  4, ..., 17, 19,  5],\n",
       "       [ 2,  2, 10, ..., 20, 15,  8],\n",
       "       ...,\n",
       "       [13, 13, 13, ..., 28, 13, 13],\n",
       "       [ 0,  1,  0, ..., 35,  5,  0],\n",
       "       [15,  2,  2, ..., 37, 22,  9]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1acc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
