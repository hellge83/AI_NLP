{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4d1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# import tensorflow as tf\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# gpu = gpus[0]\n",
    "# tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea745db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9613cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import PorterStemmer\n",
    "import spacy ### не работает нормально совместно с tf gpu + подгружать до tf\n",
    "from spacy import displacy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec013882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpu = gpus[0]\n",
    "tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalMaxPooling1D, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f29adb",
   "metadata": {},
   "source": [
    "### get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dabf7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "\n",
    "# gauth = GoogleAuth()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7374e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded = drive.CreateFile({'id': '1d1-5FwxK53ePwygNWeG7jhsOWZbi5HOv'})\n",
    "# downloaded.GetContentFile('train_docs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3bb5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded = drive.CreateFile({'id': '1MMOY477t965G0C5DtXeREVp0X85UaNq5'})\n",
    "# downloaded.GetContentFile('test_docs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d540ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('D:/GeekBrains/nlp/les06/IMDB_sentiment_dataset.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b9e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74269435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 25000\n",
      "Test size = 25000\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.tsv\", delimiter=\"\\t\", encoding = 'utf8')\n",
    "test_df = pd.read_csv(\"test.tsv\", delimiter=\"\\t\", encoding = 'utf8')\n",
    "\n",
    "print('Train size = {}'.format(len(train_df)))\n",
    "print('Test size = {}'.format(len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "231e0a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_positive</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dreamgirls, despite its fistful of Tony wins i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This show comes up with interesting locations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I simply love this movie. I also love the Ramo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Spoilers ahead if you want to call them that.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>My all-time favorite movie! I have seen many m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_positive                                             review\n",
       "0            0  Dreamgirls, despite its fistful of Tony wins i...\n",
       "1            0  This show comes up with interesting locations ...\n",
       "2            1  I simply love this movie. I also love the Ramo...\n",
       "3            0  Spoilers ahead if you want to call them that.....\n",
       "4            1  My all-time favorite movie! I have seen many m..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2df57e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищенный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•`'·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(\"[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(\"\\\\'\", \"'\", text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", '', text)\n",
    "    text = re.sub(r'[\\xad]', '', text.strip())\n",
    "\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "610d1016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Wonderful film, one of the best horror films of the 70s. She is realistic settings and atmospheres. As usual it was inevitable the usual negative comments. I have noticed that most horror films of a certain period many times fail to reach even sufficiency. Obviously because most horror movies are old and must be denigrati, is like a mental mechanism that moves the minds of the potential of music critics here.<br /><br />Before you read the review already knew what was the final judgment. In the film a good gift because 10 is really well done. Raines reads quite well and the film as a way in which it was produced reminds me a lot of Kubrick films. He really impression. Excellent film really. I consider a film anthology of years'70.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = train_df['review'].iloc[5]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea0eee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Possible nested set at position 41\n",
      "  \n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Possible nested set at position 6\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Wonderful film one of the best horror films of the s She is realistic settings and atmospheres As usual it was inevitable the usual negative comments I have noticed that most horror films of a certain period many times fail to reach even sufficiency Obviously because most horror movies are old and must be denigrati is like a mental mechanism that moves the minds of the potential of music critics here  Before you read the review already knew what was the final judgment In the film a good gift because  is really well done Raines reads quite well and the film as a way in which it was produced reminds me a lot of Kubrick films He really impression Excellent film really I consider a film anthology of years'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68fccf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review'] = train_df['review'].apply(lambda text: clean_text(text))\n",
    "test_df['review'] = test_df['review'].apply(lambda text: clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "474ec887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 71.22%\n"
     ]
    }
   ],
   "source": [
    "#@title Начинаем классифицировать! { vertical-output: true, display-mode: \"form\" }\n",
    "positive_words = 'love', 'great', 'best', 'wonderful', 'favorite', 'memorable', 'popular', 'hooked'#@param {type:\"raw\"}\n",
    "negative_words = 'worst', 'awful', 'crap', 'poor', 'terrible', 'boring', 'dreadful', 'worse', 'confusing', 'bad' #@param {type:\"raw\"}\n",
    "\n",
    "positives_count = test_df.review.apply(lambda text: sum(word in text for word in positive_words))\n",
    "negatives_count = test_df.review.apply(lambda text: sum(word in text for word in negative_words))\n",
    "is_positive = positives_count > negatives_count\n",
    "correct_count = (is_positive == test_df.is_positive).values.sum()\n",
    "\n",
    "accuracy = correct_count / len(test_df)\n",
    "\n",
    "print('Test accuracy = {:.2%}'.format(accuracy))\n",
    "# if accuracy > 0.71:\n",
    "#     from IPython.display import Image, display\n",
    "#     display(Image('https://s3.amazonaws.com/achgen360/t/rmmoZsub.png', width=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "226a364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "res['keywords'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9048b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "826fc6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1178"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword_en = stopwords.words('english')\n",
    "with open('stopwords.txt', encoding='utf8') as f:\n",
    "    additional_stopwords = set([w.strip() for w in f.readlines() if w]) # from https://github.com/stopwords-iso and others\n",
    "stopword_en += list(additional_stopwords)\n",
    "len(stopword_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d69b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_en] # [6]\n",
    "    words_lem_without_stopwords = ' '.join(words_lem_without_stopwords) #list to string\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a3ea974",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache2 = {}\n",
    "def stem(text, stemmer):\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_stem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache2: # [4]\n",
    "                words_stem.append(cache2[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache2[w] = stemmer.stem(w)\n",
    "                words_stem.append(temp_cach)\n",
    "    \n",
    "    words_stem_without_stopwords=[i for i in words_stem if not i in stopword_en] # [6]\n",
    "    words_stem_without_stopwords = ' '.join(words_stem_without_stopwords) #list to string\n",
    "    \n",
    "    return words_stem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c980c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review_lem'] = train_df['review'].apply(lambda text: lemmatization(text))\n",
    "test_df['review_lem'] = test_df['review'].apply(lambda text: lemmatization(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "417a70bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    \n",
    "    return accuracy_score(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7444ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(X_train, y_train, X_test, y_test, classifier, vectorizer):\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return eval_model(model, X_test, y_test), classifier, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b63199",
   "metadata": {},
   "source": [
    "#### count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5bb2c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224, 'count_vect': 0.85692}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review'], train_df['is_positive'], test_df['review'], test_df['is_positive'], LogisticRegression(), CountVectorizer(stop_words = stopword_en, min_df = 0.01))\n",
    "res['count_vect'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d5efbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224, 'count_vect': 0.85692, 'count_vect_lem': 0.85692}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review_lem'], train_df['is_positive'], test_df['review_lem'], test_df['is_positive'], LogisticRegression(), CountVectorizer(stop_words = stopword_en, min_df = 0.01))\n",
    "res['count_vect_lem'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ba4ee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.80%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.741\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wonderfully\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.06%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.313\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        funniest\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.159\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        subtle\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.140\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        delightful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.48%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.139\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        rare\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.77%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.104\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        excellent\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.49%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.019\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        perfectly\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.015\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        finest\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.994\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        surprisingly\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.991\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        incredible\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.75%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.989\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        favorite\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.95%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.966\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        favourite\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.952\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        superb\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.40%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.915\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        perfect\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.40%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 753 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.34%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 715 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.922\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        garbage\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.932\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        save\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.961\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mediocre\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.50%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.018\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        horrible\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.50%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.018\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        boring\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.063\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        pathetic\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.99%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.078\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wasted\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.079\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        disappointing\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.081\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        annoying\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.090\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        badly\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.096\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        bland\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.55%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.131\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        worse\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.140\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mess\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.189\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        fails\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.267\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wooden\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.92%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.332\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        avoid\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.356\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dull\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.395\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        lacks\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.18%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.425\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        awful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.428\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        laughable\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.569\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        redeeming\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.595\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        pointless\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.608\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        worst\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.704\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        poorly\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.982\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        disappointment\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.993\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        waste\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "eli5.show_weights(clf, vec = vect, top=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b851918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=positive\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.000</b>, score <b>-8.575</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.031\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -8.544\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 97.48%); opacity: 0.80\" title=\"-0.021\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.95%); opacity: 0.96\" title=\"-0.858\">terrible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.51%); opacity: 0.83\" title=\"-0.182\">difficult</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.81%); opacity: 0.82\" title=\"-0.132\">believe</span><span style=\"opacity: 0.80\"> katie heartfelt teenager </span><span style=\"background-color: hsl(0, 100.00%, 86.71%); opacity: 0.84\" title=\"-0.224\">power</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 63.94%); opacity: 0.97\" title=\"-0.932\">save</span><span style=\"opacity: 0.80\"> pity chinese </span><span style=\"background-color: hsl(120, 100.00%, 95.86%); opacity: 0.81\" title=\"0.042\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.48%); opacity: 0.80\" title=\"-0.021\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.67%); opacity: 0.83\" title=\"-0.178\">didnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.71%); opacity: 0.81\" title=\"-0.060\">convincing</span><span style=\"opacity: 0.80\"> argument </span><span style=\"background-color: hsl(0, 100.00%, 76.61%); opacity: 0.89\" title=\"-0.502\">prove</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.92%); opacity: 0.83\" title=\"-0.151\">rest</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.16%); opacity: 0.84\" title=\"-0.213\">plot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.67%); opacity: 0.83\" title=\"-0.178\">didnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.65%); opacity: 0.92\" title=\"-0.661\">effort</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.21%); opacity: 0.88\" title=\"-0.424\">cheap</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.91%); opacity: 0.82\" title=\"-0.130\">common</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.20%); opacity: 0.81\" title=\"-0.052\">sense</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.16%); opacity: 0.84\" title=\"-0.213\">plot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.02%); opacity: 0.94\" title=\"-0.750\">ridiculous</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.06%); opacity: 0.82\" title=\"-0.127\">thing</span><span style=\"opacity: 0.80\"> extract demonstrate arrogant </span><span style=\"background-color: hsl(120, 100.00%, 84.02%); opacity: 0.85\" title=\"0.291\">human</span><span style=\"opacity: 0.80\"> katie inherited arrogance </span><span style=\"background-color: hsl(0, 100.00%, 84.76%); opacity: 0.85\" title=\"-0.272\">mother</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.081\">annoying</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.97%); opacity: 0.81\" title=\"-0.027\">character</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.08%); opacity: 0.85\" title=\"0.264\">seen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.90%); opacity: 0.81\" title=\"-0.074\">long</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.25%); opacity: 0.82\" title=\"0.085\">time</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.97%); opacity: 0.82\" title=\"-0.129\">acting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.80%); opacity: 0.85\" title=\"-0.271\">scenery</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.47%); opacity: 0.87\" title=\"-0.388\">ok</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.16%); opacity: 0.84\" title=\"-0.213\">plot</span><span style=\"opacity: 0.80\"> ruins </span><span style=\"background-color: hsl(0, 100.00%, 79.21%); opacity: 0.88\" title=\"-0.424\">cheap</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.50%); opacity: 0.83\" title=\"-0.182\">clichés</span><span style=\"opacity: 0.80\"> hypocritical </span><span style=\"background-color: hsl(0, 100.00%, 92.50%); opacity: 0.82\" title=\"-0.099\">scenes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.41%); opacity: 0.84\" title=\"0.231\">expect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.48%); opacity: 0.80\" title=\"-0.021\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.33%); opacity: 0.83\" title=\"0.164\">life</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.99%); opacity: 0.88\" title=\"-0.431\">skip</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Positive' if test_df['is_positive'].iloc[6] else 'Negative')\n",
    "eli5.show_prediction(clf, test_df['review_lem'].iloc[6], vec = vect, \n",
    "                     targets=['positive'], target_names=['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c55dca",
   "metadata": {},
   "source": [
    "#### tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23a44f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review'], train_df['is_positive'], test_df['review'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba8497",
   "metadata": {},
   "source": [
    "с tfidf результат чуть выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac439673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review_lem'], train_df['is_positive'], test_df['review_lem'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_lem'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d05ce8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.854\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        excellent\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.600\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        great\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.515\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        best\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.466\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        perfect\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.74%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.374\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wonderful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.292\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        favorite\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.013\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        amazing\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.55%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.484\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        loved\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.376\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        fantastic\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.356\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wonderfully\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.323\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        highly\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.237\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        superb\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.07%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 750 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.10%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 718 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.10%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.226\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        laughable\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.05%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.246\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        minutes\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.298\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        instead\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.310\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        badly\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.36%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.573\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        lame\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.642\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        save\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.652\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        lacks\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.19%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.655\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        supposed\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.687\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ridiculous\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.745\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mess\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.88%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.807\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        disappointing\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.64%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.925\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        pointless\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.54%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.974\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        avoid\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.078\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        unfortunately\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.24%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.121\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        fails\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.10%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.193\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        annoying\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.245\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        horrible\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.468\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        disappointment\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.495\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        terrible\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.718\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        poorly\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.780\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        poor\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.92%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.800\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dull\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.960\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        worse\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.342\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        boring\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.838\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        bad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.412\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        awful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.18%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.876\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        waste\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -8.803\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        worst\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(clf, vec = vect, top=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e51b7ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=positive\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.002</b>, score <b>-6.078</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.18%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.063\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.015\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 96.61%); opacity: 0.81\" title=\"-0.021\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.84%); opacity: 0.99\" title=\"-0.682\">terrible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.51%); opacity: 0.82\" title=\"-0.064\">difficult</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.56%); opacity: 0.83\" title=\"-0.118\">believe</span><span style=\"opacity: 0.80\"> katie heartfelt teenager </span><span style=\"background-color: hsl(0, 100.00%, 96.12%); opacity: 0.81\" title=\"-0.025\">power</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.12%); opacity: 0.97\" title=\"-0.602\">save</span><span style=\"opacity: 0.80\"> pity chinese </span><span style=\"background-color: hsl(120, 100.00%, 95.90%); opacity: 0.81\" title=\"0.027\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.61%); opacity: 0.81\" title=\"-0.021\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.01%); opacity: 0.85\" title=\"-0.173\">didnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.35%); opacity: 0.81\" title=\"0.043\">convincing</span><span style=\"opacity: 0.80\"> argument </span><span style=\"background-color: hsl(0, 100.00%, 86.13%); opacity: 0.84\" title=\"-0.155\">prove</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.37%); opacity: 0.85\" title=\"-0.167\">rest</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.30%); opacity: 0.86\" title=\"-0.202\">plot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.01%); opacity: 0.85\" title=\"-0.173\">didnt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.56%); opacity: 0.92\" title=\"-0.432\">effort</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.23%); opacity: 0.90\" title=\"-0.355\">cheap</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.38%); opacity: 0.81\" title=\"-0.043\">common</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.48%); opacity: 0.83\" title=\"-0.104\">sense</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.30%); opacity: 0.86\" title=\"-0.202\">plot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 63.44%); opacity: 0.98\" title=\"-0.618\">ridiculous</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.63%); opacity: 0.85\" title=\"-0.179\">thing</span><span style=\"opacity: 0.80\"> extract demonstrate arrogant </span><span style=\"background-color: hsl(120, 100.00%, 80.13%); opacity: 0.87\" title=\"0.259\">human</span><span style=\"opacity: 0.80\"> katie inherited arrogance </span><span style=\"background-color: hsl(0, 100.00%, 86.11%); opacity: 0.84\" title=\"-0.155\">mother</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.703\">annoying</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.51%); opacity: 0.81\" title=\"-0.031\">character</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.38%); opacity: 0.85\" title=\"0.184\">seen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.16%); opacity: 0.81\" title=\"-0.034\">long</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.14%); opacity: 0.82\" title=\"0.069\">time</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.64%); opacity: 0.84\" title=\"-0.131\">acting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.61%); opacity: 0.82\" title=\"-0.063\">scenery</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.09%); opacity: 0.88\" title=\"-0.298\">ok</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.30%); opacity: 0.86\" title=\"-0.202\">plot</span><span style=\"opacity: 0.80\"> ruins </span><span style=\"background-color: hsl(0, 100.00%, 75.23%); opacity: 0.90\" title=\"-0.355\">cheap</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.31%); opacity: 0.85\" title=\"-0.185\">clichés</span><span style=\"opacity: 0.80\"> hypocritical </span><span style=\"background-color: hsl(0, 100.00%, 93.11%); opacity: 0.82\" title=\"-0.057\">scenes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.61%); opacity: 0.83\" title=\"0.117\">expect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.61%); opacity: 0.81\" title=\"-0.021\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.37%); opacity: 0.85\" title=\"0.184\">life</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.59%); opacity: 0.89\" title=\"-0.327\">skip</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Positive' if test_df['is_positive'].iloc[6] else 'Negative')\n",
    "eli5.show_prediction(clf, test_df['review_lem'].iloc[6], vec = vect, \n",
    "                     targets=['positive'], target_names=['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c51ac4",
   "metadata": {},
   "source": [
    "качество от наличия лемматизации не изменилось"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb84c8",
   "metadata": {},
   "source": [
    "#### word n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34952063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review'], train_df['is_positive'], test_df['review'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(ngram_range=(1, 2), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_n12'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ad7debe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748,\n",
       " 'tfidf_vect_n13': 0.86748}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review'], train_df['is_positive'], test_df['review'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(ngram_range=(1, 3), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_n13'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0915e61",
   "metadata": {},
   "source": [
    "добавление биграмм немного улучшает результат, дальнейшее увеличение ничего не меняет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b459b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748,\n",
       " 'tfidf_vect_n13': 0.86748,\n",
       " 'tfidf_vect_n22': 0.62112}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review'], train_df['is_positive'], test_df['review'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(ngram_range=(2, 2), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_n22'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb9885",
   "metadata": {},
   "source": [
    "только пары слов (без униграмм) сильно ухудшили результат"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dff244",
   "metadata": {},
   "source": [
    "#### char n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e900eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748,\n",
       " 'tfidf_vect_n13': 0.86748,\n",
       " 'tfidf_vect_n22': 0.62112,\n",
       " 'tfidf_vect_nc26': 0.88748}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review'], train_df['is_positive'], test_df['review'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(analyzer='char', ngram_range=(2, 6), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_nc26'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d8a2877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=positive\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.011</b>, score <b>-4.492</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.036\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.455\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 99.14%); opacity: 0.80\" title=\"-0.000\">m</span><span style=\"background-color: hsl(120, 100.00%, 97.68%); opacity: 0.80\" title=\"0.002\">o</span><span style=\"background-color: hsl(0, 100.00%, 96.87%); opacity: 0.81\" title=\"-0.003\">v</span><span style=\"background-color: hsl(0, 100.00%, 96.54%); opacity: 0.81\" title=\"-0.004\">i</span><span style=\"background-color: hsl(0, 100.00%, 98.38%); opacity: 0.80\" title=\"-0.001\">e</span><span style=\"background-color: hsl(0, 100.00%, 93.56%); opacity: 0.81\" title=\"-0.009\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.80%); opacity: 0.84\" title=\"-0.025\">t</span><span style=\"background-color: hsl(0, 100.00%, 81.47%); opacity: 0.87\" title=\"-0.040\">e</span><span style=\"background-color: hsl(0, 100.00%, 71.98%); opacity: 0.92\" title=\"-0.072\">r</span><span style=\"background-color: hsl(0, 100.00%, 63.41%); opacity: 0.98\" title=\"-0.106\">r</span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.120\">i</span><span style=\"background-color: hsl(0, 100.00%, 60.42%); opacity: 1.00\" title=\"-0.119\">b</span><span style=\"background-color: hsl(0, 100.00%, 70.02%); opacity: 0.93\" title=\"-0.080\">l</span><span style=\"background-color: hsl(0, 100.00%, 81.95%); opacity: 0.86\" title=\"-0.039\">e</span><span style=\"background-color: hsl(0, 100.00%, 92.92%); opacity: 0.82\" title=\"-0.010\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.95%); opacity: 0.81\" title=\"0.008\">d</span><span style=\"background-color: hsl(120, 100.00%, 89.16%); opacity: 0.83\" title=\"0.019\">i</span><span style=\"background-color: hsl(120, 100.00%, 86.72%); opacity: 0.84\" title=\"0.025\">f</span><span style=\"background-color: hsl(120, 100.00%, 87.75%); opacity: 0.84\" title=\"0.022\">f</span><span style=\"background-color: hsl(120, 100.00%, 92.89%); opacity: 0.82\" title=\"0.010\">i</span><span style=\"background-color: hsl(0, 100.00%, 97.91%); opacity: 0.80\" title=\"-0.002\">c</span><span style=\"background-color: hsl(0, 100.00%, 90.66%); opacity: 0.83\" title=\"-0.015\">u</span><span style=\"background-color: hsl(0, 100.00%, 90.23%); opacity: 0.83\" title=\"-0.016\">l</span><span style=\"background-color: hsl(0, 100.00%, 91.70%); opacity: 0.82\" title=\"-0.013\">t</span><span style=\"background-color: hsl(0, 100.00%, 90.58%); opacity: 0.83\" title=\"-0.015\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.87%); opacity: 0.82\" title=\"-0.012\">b</span><span style=\"background-color: hsl(0, 100.00%, 94.44%); opacity: 0.81\" title=\"-0.007\">e</span><span style=\"background-color: hsl(0, 100.00%, 93.08%); opacity: 0.82\" title=\"-0.010\">l</span><span style=\"background-color: hsl(0, 100.00%, 94.33%); opacity: 0.81\" title=\"-0.007\">i</span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.012\">e</span><span style=\"background-color: hsl(0, 100.00%, 94.08%); opacity: 0.81\" title=\"-0.008\">v</span><span style=\"background-color: hsl(0, 100.00%, 95.20%); opacity: 0.81\" title=\"-0.006\">e</span><span style=\"background-color: hsl(0, 100.00%, 92.93%); opacity: 0.82\" title=\"-0.010\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.24%); opacity: 0.82\" title=\"-0.014\">k</span><span style=\"background-color: hsl(0, 100.00%, 91.23%); opacity: 0.82\" title=\"-0.014\">a</span><span style=\"background-color: hsl(120, 100.00%, 99.74%); opacity: 0.80\" title=\"0.000\">t</span><span style=\"background-color: hsl(120, 100.00%, 93.50%); opacity: 0.81\" title=\"0.009\">i</span><span style=\"background-color: hsl(120, 100.00%, 93.27%); opacity: 0.82\" title=\"0.009\">e</span><span style=\"background-color: hsl(120, 100.00%, 89.85%); opacity: 0.83\" title=\"0.017\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.46%); opacity: 0.85\" title=\"0.028\">h</span><span style=\"background-color: hsl(120, 100.00%, 82.84%); opacity: 0.86\" title=\"0.036\">e</span><span style=\"background-color: hsl(120, 100.00%, 83.02%); opacity: 0.86\" title=\"0.035\">a</span><span style=\"background-color: hsl(120, 100.00%, 83.78%); opacity: 0.86\" title=\"0.033\">r</span><span style=\"background-color: hsl(120, 100.00%, 87.96%); opacity: 0.84\" title=\"0.022\">t</span><span style=\"background-color: hsl(120, 100.00%, 95.84%); opacity: 0.81\" title=\"0.005\">f</span><span style=\"background-color: hsl(120, 100.00%, 95.29%); opacity: 0.81\" title=\"0.006\">e</span><span style=\"background-color: hsl(0, 100.00%, 95.67%); opacity: 0.81\" title=\"-0.005\">l</span><span style=\"background-color: hsl(0, 100.00%, 94.18%); opacity: 0.81\" title=\"-0.008\">t</span><span style=\"background-color: hsl(0, 100.00%, 93.12%); opacity: 0.82\" title=\"-0.010\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.12%); opacity: 0.82\" title=\"-0.014\">t</span><span style=\"background-color: hsl(0, 100.00%, 92.69%); opacity: 0.82\" title=\"-0.011\">e</span><span style=\"background-color: hsl(0, 100.00%, 97.73%); opacity: 0.80\" title=\"-0.002\">e</span><span style=\"background-color: hsl(120, 100.00%, 93.77%); opacity: 0.81\" title=\"0.008\">n</span><span style=\"background-color: hsl(120, 100.00%, 90.37%); opacity: 0.83\" title=\"0.016\">a</span><span style=\"background-color: hsl(120, 100.00%, 88.89%); opacity: 0.83\" title=\"0.019\">g</span><span style=\"background-color: hsl(120, 100.00%, 89.92%); opacity: 0.83\" title=\"0.017\">e</span><span style=\"background-color: hsl(120, 100.00%, 92.69%); opacity: 0.82\" title=\"0.011\">r</span><span style=\"background-color: hsl(120, 100.00%, 98.79%); opacity: 0.80\" title=\"0.001\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.42%); opacity: 0.81\" title=\"0.005\">p</span><span style=\"background-color: hsl(120, 100.00%, 94.53%); opacity: 0.81\" title=\"0.007\">o</span><span style=\"background-color: hsl(120, 100.00%, 90.01%); opacity: 0.83\" title=\"0.017\">w</span><span style=\"background-color: hsl(120, 100.00%, 94.28%); opacity: 0.81\" title=\"0.007\">e</span><span style=\"background-color: hsl(0, 100.00%, 93.67%); opacity: 0.81\" title=\"-0.009\">r</span><span style=\"background-color: hsl(0, 100.00%, 80.32%); opacity: 0.87\" title=\"-0.044\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.54%); opacity: 0.92\" title=\"-0.070\">s</span><span style=\"background-color: hsl(0, 100.00%, 73.23%); opacity: 0.91\" title=\"-0.068\">a</span><span style=\"background-color: hsl(0, 100.00%, 77.37%); opacity: 0.89\" title=\"-0.053\">v</span><span style=\"background-color: hsl(0, 100.00%, 84.64%); opacity: 0.85\" title=\"-0.031\">e</span><span style=\"background-color: hsl(0, 100.00%, 90.40%); opacity: 0.83\" title=\"-0.016\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.53%); opacity: 0.80\" title=\"-0.002\">p</span><span style=\"background-color: hsl(120, 100.00%, 94.48%); opacity: 0.81\" title=\"0.007\">i</span><span style=\"background-color: hsl(120, 100.00%, 92.55%); opacity: 0.82\" title=\"0.011\">t</span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.001\">y</span><span style=\"background-color: hsl(120, 100.00%, 98.93%); opacity: 0.80\" title=\"0.001\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.09%); opacity: 0.80\" title=\"0.003\">c</span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.005\">h</span><span style=\"background-color: hsl(120, 100.00%, 92.53%); opacity: 0.82\" title=\"0.011\">i</span><span style=\"background-color: hsl(120, 100.00%, 90.39%); opacity: 0.83\" title=\"0.016\">n</span><span style=\"background-color: hsl(120, 100.00%, 89.02%); opacity: 0.83\" title=\"0.019\">e</span><span style=\"background-color: hsl(120, 100.00%, 95.29%); opacity: 0.81\" title=\"0.006\">s</span><span style=\"background-color: hsl(0, 100.00%, 94.89%); opacity: 0.81\" title=\"-0.006\">e</span><span style=\"background-color: hsl(0, 100.00%, 94.30%); opacity: 0.81\" title=\"-0.007\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.17%); opacity: 0.81\" title=\"-0.004\">p</span><span style=\"background-color: hsl(120, 100.00%, 96.66%); opacity: 0.81\" title=\"0.003\">e</span><span style=\"background-color: hsl(120, 100.00%, 98.57%); opacity: 0.80\" title=\"0.001\">o</span><span style=\"background-color: hsl(120, 100.00%, 94.98%); opacity: 0.81\" title=\"0.006\">p</span><span style=\"background-color: hsl(0, 100.00%, 97.61%); opacity: 0.80\" title=\"-0.002\">l</span><span style=\"background-color: hsl(0, 100.00%, 95.41%); opacity: 0.81\" title=\"-0.005\">e</span><span style=\"background-color: hsl(0, 100.00%, 95.68%); opacity: 0.81\" title=\"-0.005\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.13%); opacity: 0.81\" title=\"-0.008\">m</span><span style=\"background-color: hsl(0, 100.00%, 95.71%); opacity: 0.81\" title=\"-0.005\">o</span><span style=\"background-color: hsl(0, 100.00%, 93.09%); opacity: 0.82\" title=\"-0.010\">v</span><span style=\"background-color: hsl(0, 100.00%, 93.58%); opacity: 0.81\" title=\"-0.009\">i</span><span style=\"background-color: hsl(0, 100.00%, 97.20%); opacity: 0.80\" title=\"-0.003\">e</span><span style=\"background-color: hsl(0, 100.00%, 92.54%); opacity: 0.82\" title=\"-0.011\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.03%); opacity: 0.83\" title=\"-0.019\">d</span><span style=\"background-color: hsl(0, 100.00%, 87.67%); opacity: 0.84\" title=\"-0.022\">i</span><span style=\"background-color: hsl(0, 100.00%, 83.88%); opacity: 0.85\" title=\"-0.033\">d</span><span style=\"background-color: hsl(0, 100.00%, 84.28%); opacity: 0.85\" title=\"-0.032\">n</span><span style=\"background-color: hsl(0, 100.00%, 89.08%); opacity: 0.83\" title=\"-0.019\">t</span><span style=\"background-color: hsl(0, 100.00%, 93.83%); opacity: 0.81\" title=\"-0.008\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.87%); opacity: 0.81\" title=\"-0.005\">c</span><span style=\"background-color: hsl(0, 100.00%, 93.18%); opacity: 0.82\" title=\"-0.010\">o</span><span style=\"background-color: hsl(0, 100.00%, 87.86%); opacity: 0.84\" title=\"-0.022\">n</span><span style=\"background-color: hsl(0, 100.00%, 86.82%); opacity: 0.84\" title=\"-0.025\">v</span><span style=\"background-color: hsl(0, 100.00%, 85.21%); opacity: 0.85\" title=\"-0.029\">i</span><span style=\"background-color: hsl(0, 100.00%, 86.54%); opacity: 0.84\" title=\"-0.025\">n</span><span style=\"background-color: hsl(0, 100.00%, 90.72%); opacity: 0.82\" title=\"-0.015\">c</span><span style=\"background-color: hsl(0, 100.00%, 87.93%); opacity: 0.84\" title=\"-0.022\">i</span><span style=\"background-color: hsl(0, 100.00%, 87.48%); opacity: 0.84\" title=\"-0.023\">n</span><span style=\"background-color: hsl(0, 100.00%, 86.78%); opacity: 0.84\" title=\"-0.025\">g</span><span style=\"background-color: hsl(0, 100.00%, 86.95%); opacity: 0.84\" title=\"-0.024\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.95%); opacity: 0.83\" title=\"-0.019\">a</span><span style=\"background-color: hsl(0, 100.00%, 85.19%); opacity: 0.85\" title=\"-0.029\">r</span><span style=\"background-color: hsl(0, 100.00%, 86.19%); opacity: 0.84\" title=\"-0.026\">g</span><span style=\"background-color: hsl(0, 100.00%, 90.45%); opacity: 0.83\" title=\"-0.016\">u</span><span style=\"background-color: hsl(0, 100.00%, 96.70%); opacity: 0.81\" title=\"-0.003\">m</span><span style=\"background-color: hsl(120, 100.00%, 96.50%); opacity: 0.81\" title=\"0.004\">e</span><span style=\"background-color: hsl(120, 100.00%, 99.00%); opacity: 0.80\" title=\"0.001\">n</span><span style=\"background-color: hsl(0, 100.00%, 96.41%); opacity: 0.81\" title=\"-0.004\">t</span><span style=\"background-color: hsl(0, 100.00%, 93.67%); opacity: 0.81\" title=\"-0.009\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.14%); opacity: 0.81\" title=\"-0.008\">p</span><span style=\"background-color: hsl(0, 100.00%, 94.88%); opacity: 0.81\" title=\"-0.006\">r</span><span style=\"background-color: hsl(120, 100.00%, 94.30%); opacity: 0.81\" title=\"0.007\">o</span><span style=\"background-color: hsl(120, 100.00%, 90.78%); opacity: 0.82\" title=\"0.015\">v</span><span style=\"background-color: hsl(120, 100.00%, 98.87%); opacity: 0.80\" title=\"0.001\">e</span><span style=\"background-color: hsl(0, 100.00%, 95.07%); opacity: 0.81\" title=\"-0.006\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.43%); opacity: 0.82\" title=\"-0.013\">r</span><span style=\"background-color: hsl(0, 100.00%, 94.06%); opacity: 0.81\" title=\"-0.008\">e</span><span style=\"background-color: hsl(0, 100.00%, 92.15%); opacity: 0.82\" title=\"-0.012\">s</span><span style=\"background-color: hsl(0, 100.00%, 91.96%); opacity: 0.82\" title=\"-0.012\">t</span><span style=\"background-color: hsl(0, 100.00%, 87.00%); opacity: 0.84\" title=\"-0.024\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.77%); opacity: 0.86\" title=\"-0.036\">p</span><span style=\"background-color: hsl(0, 100.00%, 81.82%); opacity: 0.86\" title=\"-0.039\">l</span><span style=\"background-color: hsl(0, 100.00%, 84.21%); opacity: 0.85\" title=\"-0.032\">o</span><span style=\"background-color: hsl(0, 100.00%, 85.88%); opacity: 0.85\" title=\"-0.027\">t</span><span style=\"background-color: hsl(0, 100.00%, 87.03%); opacity: 0.84\" title=\"-0.024\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.27%); opacity: 0.84\" title=\"-0.023\">d</span><span style=\"background-color: hsl(0, 100.00%, 84.91%); opacity: 0.85\" title=\"-0.030\">i</span><span style=\"background-color: hsl(0, 100.00%, 81.72%); opacity: 0.87\" title=\"-0.039\">d</span><span style=\"background-color: hsl(0, 100.00%, 82.56%); opacity: 0.86\" title=\"-0.037\">n</span><span style=\"background-color: hsl(0, 100.00%, 85.34%); opacity: 0.85\" title=\"-0.029\">t</span><span style=\"background-color: hsl(0, 100.00%, 86.62%); opacity: 0.84\" title=\"-0.025\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.08%); opacity: 0.84\" title=\"-0.027\">e</span><span style=\"background-color: hsl(0, 100.00%, 83.28%); opacity: 0.86\" title=\"-0.035\">f</span><span style=\"background-color: hsl(0, 100.00%, 80.56%); opacity: 0.87\" title=\"-0.043\">f</span><span style=\"background-color: hsl(0, 100.00%, 80.34%); opacity: 0.87\" title=\"-0.044\">o</span><span style=\"background-color: hsl(0, 100.00%, 85.01%); opacity: 0.85\" title=\"-0.030\">r</span><span style=\"background-color: hsl(0, 100.00%, 92.08%); opacity: 0.82\" title=\"-0.012\">t</span><span style=\"background-color: hsl(0, 100.00%, 89.73%); opacity: 0.83\" title=\"-0.017\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.65%); opacity: 0.85\" title=\"-0.028\">c</span><span style=\"background-color: hsl(0, 100.00%, 81.39%); opacity: 0.87\" title=\"-0.040\">h</span><span style=\"background-color: hsl(0, 100.00%, 77.98%); opacity: 0.89\" title=\"-0.051\">e</span><span style=\"background-color: hsl(0, 100.00%, 73.23%); opacity: 0.91\" title=\"-0.068\">a</span><span style=\"background-color: hsl(0, 100.00%, 75.83%); opacity: 0.90\" title=\"-0.059\">p</span><span style=\"background-color: hsl(0, 100.00%, 87.07%); opacity: 0.84\" title=\"-0.024\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.03%); opacity: 0.82\" title=\"0.012\">c</span><span style=\"background-color: hsl(120, 100.00%, 91.38%); opacity: 0.82\" title=\"0.013\">o</span><span style=\"background-color: hsl(120, 100.00%, 88.61%); opacity: 0.83\" title=\"0.020\">m</span><span style=\"background-color: hsl(120, 100.00%, 88.92%); opacity: 0.83\" title=\"0.019\">m</span><span style=\"background-color: hsl(120, 100.00%, 93.61%); opacity: 0.81\" title=\"0.009\">o</span><span style=\"background-color: hsl(0, 100.00%, 99.07%); opacity: 0.80\" title=\"-0.001\">n</span><span style=\"background-color: hsl(0, 100.00%, 95.73%); opacity: 0.81\" title=\"-0.005\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.92%); opacity: 0.82\" title=\"-0.014\">s</span><span style=\"background-color: hsl(0, 100.00%, 94.72%); opacity: 0.81\" title=\"-0.007\">e</span><span style=\"background-color: hsl(0, 100.00%, 95.18%); opacity: 0.81\" title=\"-0.006\">n</span><span style=\"background-color: hsl(0, 100.00%, 91.08%); opacity: 0.82\" title=\"-0.014\">s</span><span style=\"background-color: hsl(0, 100.00%, 90.98%); opacity: 0.82\" title=\"-0.014\">e</span><span style=\"background-color: hsl(0, 100.00%, 85.82%); opacity: 0.85\" title=\"-0.027\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.45%); opacity: 0.87\" title=\"-0.040\">p</span><span style=\"background-color: hsl(0, 100.00%, 82.08%); opacity: 0.86\" title=\"-0.038\">l</span><span style=\"background-color: hsl(0, 100.00%, 80.63%); opacity: 0.87\" title=\"-0.043\">o</span><span style=\"background-color: hsl(0, 100.00%, 85.59%); opacity: 0.85\" title=\"-0.028\">t</span><span style=\"background-color: hsl(0, 100.00%, 86.98%); opacity: 0.84\" title=\"-0.024\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.31%); opacity: 0.86\" title=\"-0.035\">r</span><span style=\"background-color: hsl(0, 100.00%, 75.13%); opacity: 0.90\" title=\"-0.061\">i</span><span style=\"background-color: hsl(0, 100.00%, 67.38%); opacity: 0.95\" title=\"-0.090\">d</span><span style=\"background-color: hsl(0, 100.00%, 66.49%); opacity: 0.96\" title=\"-0.094\">i</span><span style=\"background-color: hsl(0, 100.00%, 66.49%); opacity: 0.96\" title=\"-0.094\">c</span><span style=\"background-color: hsl(0, 100.00%, 67.48%); opacity: 0.95\" title=\"-0.090\">u</span><span style=\"background-color: hsl(0, 100.00%, 70.78%); opacity: 0.93\" title=\"-0.077\">l</span><span style=\"background-color: hsl(0, 100.00%, 74.45%); opacity: 0.91\" title=\"-0.063\">o</span><span style=\"background-color: hsl(0, 100.00%, 79.64%); opacity: 0.88\" title=\"-0.046\">u</span><span style=\"background-color: hsl(0, 100.00%, 85.43%); opacity: 0.85\" title=\"-0.028\">s</span><span style=\"background-color: hsl(0, 100.00%, 90.42%); opacity: 0.83\" title=\"-0.016\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.14%); opacity: 0.84\" title=\"-0.024\">t</span><span style=\"background-color: hsl(0, 100.00%, 88.10%); opacity: 0.84\" title=\"-0.021\">h</span><span style=\"background-color: hsl(0, 100.00%, 86.26%); opacity: 0.84\" title=\"-0.026\">i</span><span style=\"background-color: hsl(0, 100.00%, 86.05%); opacity: 0.84\" title=\"-0.027\">n</span><span style=\"background-color: hsl(0, 100.00%, 86.71%); opacity: 0.84\" title=\"-0.025\">g</span><span style=\"background-color: hsl(0, 100.00%, 91.47%); opacity: 0.82\" title=\"-0.013\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.96%); opacity: 0.80\" title=\"0.002\">e</span><span style=\"background-color: hsl(120, 100.00%, 93.66%); opacity: 0.81\" title=\"0.009\">x</span><span style=\"background-color: hsl(120, 100.00%, 90.51%); opacity: 0.83\" title=\"0.015\">t</span><span style=\"background-color: hsl(120, 100.00%, 91.59%); opacity: 0.82\" title=\"0.013\">r</span><span style=\"background-color: hsl(120, 100.00%, 95.26%); opacity: 0.81\" title=\"0.006\">a</span><span style=\"background-color: hsl(0, 100.00%, 96.86%); opacity: 0.81\" title=\"-0.003\">c</span><span style=\"background-color: hsl(0, 100.00%, 99.91%); opacity: 0.80\" title=\"-0.000\">t</span><span style=\"background-color: hsl(120, 100.00%, 97.38%); opacity: 0.80\" title=\"0.002\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.77%); opacity: 0.80\" title=\"0.002\">d</span><span style=\"background-color: hsl(120, 100.00%, 93.53%); opacity: 0.81\" title=\"0.009\">e</span><span style=\"background-color: hsl(0, 100.00%, 97.43%); opacity: 0.80\" title=\"-0.002\">m</span><span style=\"background-color: hsl(0, 100.00%, 95.78%); opacity: 0.81\" title=\"-0.005\">o</span><span style=\"background-color: hsl(0, 100.00%, 91.49%); opacity: 0.82\" title=\"-0.013\">n</span><span style=\"background-color: hsl(0, 100.00%, 91.59%); opacity: 0.82\" title=\"-0.013\">s</span><span style=\"background-color: hsl(0, 100.00%, 95.38%); opacity: 0.81\" title=\"-0.006\">t</span><span style=\"background-color: hsl(120, 100.00%, 96.38%); opacity: 0.81\" title=\"0.004\">r</span><span style=\"background-color: hsl(120, 100.00%, 95.77%); opacity: 0.81\" title=\"0.005\">a</span><span style=\"background-color: hsl(0, 100.00%, 97.57%); opacity: 0.80\" title=\"-0.002\">t</span><span style=\"background-color: hsl(0, 100.00%, 97.18%); opacity: 0.80\" title=\"-0.003\">e</span><span style=\"background-color: hsl(120, 100.00%, 97.82%); opacity: 0.80\" title=\"0.002\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.66%); opacity: 0.80\" title=\"-0.001\">a</span><span style=\"background-color: hsl(0, 100.00%, 95.95%); opacity: 0.81\" title=\"-0.005\">r</span><span style=\"background-color: hsl(0, 100.00%, 93.82%); opacity: 0.81\" title=\"-0.008\">r</span><span style=\"background-color: hsl(0, 100.00%, 95.48%); opacity: 0.81\" title=\"-0.005\">o</span><span style=\"background-color: hsl(0, 100.00%, 95.12%); opacity: 0.81\" title=\"-0.006\">g</span><span style=\"background-color: hsl(0, 100.00%, 98.73%); opacity: 0.80\" title=\"-0.001\">a</span><span style=\"background-color: hsl(0, 100.00%, 98.74%); opacity: 0.80\" title=\"-0.001\">n</span><span style=\"background-color: hsl(0, 100.00%, 96.89%); opacity: 0.81\" title=\"-0.003\">t</span><span style=\"background-color: hsl(120, 100.00%, 93.75%); opacity: 0.81\" title=\"0.009\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.68%); opacity: 0.84\" title=\"0.022\">h</span><span style=\"background-color: hsl(120, 100.00%, 85.72%); opacity: 0.85\" title=\"0.028\">u</span><span style=\"background-color: hsl(120, 100.00%, 83.74%); opacity: 0.86\" title=\"0.033\">m</span><span style=\"background-color: hsl(120, 100.00%, 84.94%); opacity: 0.85\" title=\"0.030\">a</span><span style=\"background-color: hsl(120, 100.00%, 87.71%); opacity: 0.84\" title=\"0.022\">n</span><span style=\"background-color: hsl(120, 100.00%, 97.33%); opacity: 0.80\" title=\"0.003\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.19%); opacity: 0.82\" title=\"-0.012\">k</span><span style=\"background-color: hsl(0, 100.00%, 91.95%); opacity: 0.82\" title=\"-0.012\">a</span><span style=\"background-color: hsl(120, 100.00%, 99.74%); opacity: 0.80\" title=\"0.000\">t</span><span style=\"background-color: hsl(120, 100.00%, 95.35%); opacity: 0.81\" title=\"0.006\">i</span><span style=\"background-color: hsl(120, 100.00%, 95.77%); opacity: 0.81\" title=\"0.005\">e</span><span style=\"background-color: hsl(120, 100.00%, 95.70%); opacity: 0.81\" title=\"0.005\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.11%); opacity: 0.80\" title=\"0.002\">i</span><span style=\"background-color: hsl(0, 100.00%, 98.07%); opacity: 0.80\" title=\"-0.002\">n</span><span style=\"background-color: hsl(120, 100.00%, 96.89%); opacity: 0.81\" title=\"0.003\">h</span><span style=\"background-color: hsl(120, 100.00%, 96.27%); opacity: 0.81\" title=\"0.004\">e</span><span style=\"background-color: hsl(120, 100.00%, 96.77%); opacity: 0.81\" title=\"0.003\">r</span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.006\">i</span><span style=\"background-color: hsl(0, 100.00%, 99.31%); opacity: 0.80\" title=\"-0.000\">t</span><span style=\"background-color: hsl(0, 100.00%, 92.49%); opacity: 0.82\" title=\"-0.011\">e</span><span style=\"background-color: hsl(0, 100.00%, 90.93%); opacity: 0.82\" title=\"-0.014\">d</span><span style=\"background-color: hsl(0, 100.00%, 92.67%); opacity: 0.82\" title=\"-0.011\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.71%); opacity: 0.81\" title=\"-0.003\">a</span><span style=\"background-color: hsl(0, 100.00%, 95.41%); opacity: 0.81\" title=\"-0.005\">r</span><span style=\"background-color: hsl(0, 100.00%, 93.82%); opacity: 0.81\" title=\"-0.008\">r</span><span style=\"background-color: hsl(0, 100.00%, 95.48%); opacity: 0.81\" title=\"-0.005\">o</span><span style=\"background-color: hsl(0, 100.00%, 94.86%); opacity: 0.81\" title=\"-0.006\">g</span><span style=\"background-color: hsl(120, 100.00%, 97.11%); opacity: 0.80\" title=\"0.003\">a</span><span style=\"background-color: hsl(120, 100.00%, 92.60%); opacity: 0.82\" title=\"0.011\">n</span><span style=\"background-color: hsl(120, 100.00%, 90.47%); opacity: 0.83\" title=\"0.016\">c</span><span style=\"background-color: hsl(120, 100.00%, 92.71%); opacity: 0.82\" title=\"0.011\">e</span><span style=\"background-color: hsl(0, 100.00%, 97.93%); opacity: 0.80\" title=\"-0.002\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.58%); opacity: 0.81\" title=\"-0.009\">m</span><span style=\"background-color: hsl(0, 100.00%, 91.93%); opacity: 0.82\" title=\"-0.012\">o</span><span style=\"background-color: hsl(0, 100.00%, 90.36%); opacity: 0.83\" title=\"-0.016\">t</span><span style=\"background-color: hsl(0, 100.00%, 97.96%); opacity: 0.80\" title=\"-0.002\">h</span><span style=\"background-color: hsl(120, 100.00%, 95.98%); opacity: 0.81\" title=\"0.005\">e</span><span style=\"background-color: hsl(120, 100.00%, 97.62%); opacity: 0.80\" title=\"0.002\">r</span><span style=\"background-color: hsl(0, 100.00%, 91.75%); opacity: 0.82\" title=\"-0.013\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.09%); opacity: 0.84\" title=\"-0.027\">a</span><span style=\"background-color: hsl(0, 100.00%, 76.83%); opacity: 0.89\" title=\"-0.055\">n</span><span style=\"background-color: hsl(0, 100.00%, 65.19%); opacity: 0.96\" title=\"-0.099\">n</span><span style=\"background-color: hsl(0, 100.00%, 62.68%); opacity: 0.98\" title=\"-0.109\">o</span><span style=\"background-color: hsl(0, 100.00%, 65.95%); opacity: 0.96\" title=\"-0.096\">y</span><span style=\"background-color: hsl(0, 100.00%, 71.11%); opacity: 0.93\" title=\"-0.076\">i</span><span style=\"background-color: hsl(0, 100.00%, 78.96%); opacity: 0.88\" title=\"-0.048\">n</span><span style=\"background-color: hsl(0, 100.00%, 86.08%); opacity: 0.84\" title=\"-0.027\">g</span><span style=\"background-color: hsl(0, 100.00%, 92.41%); opacity: 0.82\" title=\"-0.011\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.17%); opacity: 0.80\" title=\"0.001\">c</span><span style=\"background-color: hsl(0, 100.00%, 97.93%); opacity: 0.80\" title=\"-0.002\">h</span><span style=\"background-color: hsl(120, 100.00%, 97.97%); opacity: 0.80\" title=\"0.002\">a</span><span style=\"background-color: hsl(0, 100.00%, 99.72%); opacity: 0.80\" title=\"-0.000\">r</span><span style=\"background-color: hsl(0, 100.00%, 95.38%); opacity: 0.81\" title=\"-0.006\">a</span><span style=\"background-color: hsl(0, 100.00%, 95.83%); opacity: 0.81\" title=\"-0.005\">c</span><span style=\"background-color: hsl(0, 100.00%, 92.80%); opacity: 0.82\" title=\"-0.010\">t</span><span style=\"background-color: hsl(0, 100.00%, 93.85%); opacity: 0.81\" title=\"-0.008\">e</span><span style=\"background-color: hsl(0, 100.00%, 91.43%); opacity: 0.82\" title=\"-0.013\">r</span><span style=\"background-color: hsl(0, 100.00%, 91.81%); opacity: 0.82\" title=\"-0.013\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.11%); opacity: 0.80\" title=\"-0.001\">s</span><span style=\"background-color: hsl(120, 100.00%, 92.47%); opacity: 0.82\" title=\"0.011\">e</span><span style=\"background-color: hsl(120, 100.00%, 91.35%); opacity: 0.82\" title=\"0.014\">e</span><span style=\"background-color: hsl(120, 100.00%, 91.80%); opacity: 0.82\" title=\"0.013\">n</span><span style=\"background-color: hsl(120, 100.00%, 96.08%); opacity: 0.81\" title=\"0.004\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.22%); opacity: 0.80\" title=\"-0.000\">l</span><span style=\"background-color: hsl(120, 100.00%, 94.52%); opacity: 0.81\" title=\"0.007\">o</span><span style=\"background-color: hsl(120, 100.00%, 94.81%); opacity: 0.81\" title=\"0.007\">n</span><span style=\"background-color: hsl(120, 100.00%, 98.97%); opacity: 0.80\" title=\"0.001\">g</span><span style=\"background-color: hsl(120, 100.00%, 97.41%); opacity: 0.80\" title=\"0.002\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.21%); opacity: 0.82\" title=\"0.012\">t</span><span style=\"background-color: hsl(120, 100.00%, 88.07%); opacity: 0.84\" title=\"0.021\">i</span><span style=\"background-color: hsl(120, 100.00%, 90.40%); opacity: 0.83\" title=\"0.016\">m</span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.006\">e</span><span style=\"background-color: hsl(0, 100.00%, 97.62%); opacity: 0.80\" title=\"-0.002\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.61%); opacity: 0.82\" title=\"-0.013\">a</span><span style=\"background-color: hsl(0, 100.00%, 88.36%); opacity: 0.83\" title=\"-0.021\">c</span><span style=\"background-color: hsl(0, 100.00%, 87.99%); opacity: 0.84\" title=\"-0.022\">t</span><span style=\"background-color: hsl(0, 100.00%, 86.86%); opacity: 0.84\" title=\"-0.025\">i</span><span style=\"background-color: hsl(0, 100.00%, 85.46%); opacity: 0.85\" title=\"-0.028\">n</span><span style=\"background-color: hsl(0, 100.00%, 89.33%); opacity: 0.83\" title=\"-0.018\">g</span><span style=\"background-color: hsl(0, 100.00%, 89.16%); opacity: 0.83\" title=\"-0.019\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.15%); opacity: 0.82\" title=\"-0.014\">s</span><span style=\"background-color: hsl(0, 100.00%, 95.03%); opacity: 0.81\" title=\"-0.006\">c</span><span style=\"background-color: hsl(0, 100.00%, 93.99%); opacity: 0.81\" title=\"-0.008\">e</span><span style=\"background-color: hsl(0, 100.00%, 89.83%); opacity: 0.83\" title=\"-0.017\">n</span><span style=\"background-color: hsl(0, 100.00%, 91.69%); opacity: 0.82\" title=\"-0.013\">e</span><span style=\"background-color: hsl(0, 100.00%, 95.76%); opacity: 0.81\" title=\"-0.005\">r</span><span style=\"background-color: hsl(0, 100.00%, 98.90%); opacity: 0.80\" title=\"-0.001\">y</span><span style=\"background-color: hsl(0, 100.00%, 86.72%); opacity: 0.84\" title=\"-0.025\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.26%); opacity: 0.85\" title=\"-0.032\">o</span><span style=\"background-color: hsl(0, 100.00%, 85.09%); opacity: 0.85\" title=\"-0.029\">k</span><span style=\"background-color: hsl(0, 100.00%, 85.72%); opacity: 0.85\" title=\"-0.028\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.94%); opacity: 0.85\" title=\"-0.033\">p</span><span style=\"background-color: hsl(0, 100.00%, 83.56%); opacity: 0.86\" title=\"-0.034\">l</span><span style=\"background-color: hsl(0, 100.00%, 81.57%); opacity: 0.87\" title=\"-0.040\">o</span><span style=\"background-color: hsl(0, 100.00%, 86.00%); opacity: 0.84\" title=\"-0.027\">t</span><span style=\"background-color: hsl(0, 100.00%, 87.20%); opacity: 0.84\" title=\"-0.024\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.01%); opacity: 0.84\" title=\"-0.022\">r</span><span style=\"background-color: hsl(0, 100.00%, 89.43%); opacity: 0.83\" title=\"-0.018\">u</span><span style=\"background-color: hsl(0, 100.00%, 87.17%); opacity: 0.84\" title=\"-0.024\">i</span><span style=\"background-color: hsl(0, 100.00%, 88.36%); opacity: 0.83\" title=\"-0.021\">n</span><span style=\"background-color: hsl(0, 100.00%, 95.27%); opacity: 0.81\" title=\"-0.006\">s</span><span style=\"background-color: hsl(0, 100.00%, 92.44%); opacity: 0.82\" title=\"-0.011\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.69%); opacity: 0.86\" title=\"-0.033\">c</span><span style=\"background-color: hsl(0, 100.00%, 80.29%); opacity: 0.87\" title=\"-0.044\">h</span><span style=\"background-color: hsl(0, 100.00%, 77.89%); opacity: 0.89\" title=\"-0.052\">e</span><span style=\"background-color: hsl(0, 100.00%, 73.23%); opacity: 0.91\" title=\"-0.068\">a</span><span style=\"background-color: hsl(0, 100.00%, 75.74%); opacity: 0.90\" title=\"-0.059\">p</span><span style=\"background-color: hsl(0, 100.00%, 81.80%); opacity: 0.86\" title=\"-0.039\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.19%); opacity: 0.85\" title=\"-0.029\">c</span><span style=\"background-color: hsl(0, 100.00%, 81.29%); opacity: 0.87\" title=\"-0.041\">l</span><span style=\"background-color: hsl(0, 100.00%, 79.61%); opacity: 0.88\" title=\"-0.046\">i</span><span style=\"background-color: hsl(0, 100.00%, 77.30%); opacity: 0.89\" title=\"-0.054\">c</span><span style=\"background-color: hsl(0, 100.00%, 76.20%); opacity: 0.90\" title=\"-0.057\">h</span><span style=\"background-color: hsl(0, 100.00%, 80.04%); opacity: 0.87\" title=\"-0.045\">é</span><span style=\"background-color: hsl(0, 100.00%, 92.73%); opacity: 0.82\" title=\"-0.011\">s</span><span style=\"background-color: hsl(0, 100.00%, 95.83%); opacity: 0.81\" title=\"-0.005\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.66%); opacity: 0.83\" title=\"-0.015\">h</span><span style=\"background-color: hsl(0, 100.00%, 88.53%); opacity: 0.83\" title=\"-0.020\">y</span><span style=\"background-color: hsl(0, 100.00%, 91.92%); opacity: 0.82\" title=\"-0.012\">p</span><span style=\"background-color: hsl(0, 100.00%, 94.66%); opacity: 0.81\" title=\"-0.007\">o</span><span style=\"background-color: hsl(0, 100.00%, 98.39%); opacity: 0.80\" title=\"-0.001\">c</span><span style=\"background-color: hsl(0, 100.00%, 98.19%); opacity: 0.80\" title=\"-0.001\">r</span><span style=\"background-color: hsl(120, 100.00%, 89.86%); opacity: 0.83\" title=\"0.017\">i</span><span style=\"background-color: hsl(120, 100.00%, 87.22%); opacity: 0.84\" title=\"0.024\">t</span><span style=\"background-color: hsl(120, 100.00%, 90.49%); opacity: 0.83\" title=\"0.015\">i</span><span style=\"background-color: hsl(120, 100.00%, 93.60%); opacity: 0.81\" title=\"0.009\">c</span><span style=\"background-color: hsl(120, 100.00%, 94.80%); opacity: 0.81\" title=\"0.007\">a</span><span style=\"background-color: hsl(120, 100.00%, 90.71%); opacity: 0.82\" title=\"0.015\">l</span><span style=\"background-color: hsl(120, 100.00%, 95.00%); opacity: 0.81\" title=\"0.006\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.19%); opacity: 0.81\" title=\"-0.004\">s</span><span style=\"background-color: hsl(120, 100.00%, 98.14%); opacity: 0.80\" title=\"0.002\">c</span><span style=\"background-color: hsl(120, 100.00%, 99.21%); opacity: 0.80\" title=\"0.000\">e</span><span style=\"background-color: hsl(0, 100.00%, 96.38%); opacity: 0.81\" title=\"-0.004\">n</span><span style=\"background-color: hsl(120, 100.00%, 98.29%); opacity: 0.80\" title=\"0.001\">e</span><span style=\"background-color: hsl(120, 100.00%, 90.78%); opacity: 0.82\" title=\"0.015\">s</span><span style=\"background-color: hsl(120, 100.00%, 89.62%); opacity: 0.83\" title=\"0.018\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.00%); opacity: 0.83\" title=\"0.019\">e</span><span style=\"background-color: hsl(120, 100.00%, 88.94%); opacity: 0.83\" title=\"0.019\">x</span><span style=\"background-color: hsl(120, 100.00%, 87.77%); opacity: 0.84\" title=\"0.022\">p</span><span style=\"background-color: hsl(120, 100.00%, 87.21%); opacity: 0.84\" title=\"0.024\">e</span><span style=\"background-color: hsl(120, 100.00%, 90.77%); opacity: 0.82\" title=\"0.015\">c</span><span style=\"background-color: hsl(120, 100.00%, 95.26%); opacity: 0.81\" title=\"0.006\">t</span><span style=\"background-color: hsl(120, 100.00%, 98.88%); opacity: 0.80\" title=\"0.001\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.65%); opacity: 0.81\" title=\"-0.003\">m</span><span style=\"background-color: hsl(120, 100.00%, 97.07%); opacity: 0.80\" title=\"0.003\">o</span><span style=\"background-color: hsl(0, 100.00%, 96.82%); opacity: 0.81\" title=\"-0.003\">v</span><span style=\"background-color: hsl(0, 100.00%, 96.14%); opacity: 0.81\" title=\"-0.004\">i</span><span style=\"background-color: hsl(120, 100.00%, 97.41%); opacity: 0.80\" title=\"0.002\">e</span><span style=\"background-color: hsl(120, 100.00%, 91.29%); opacity: 0.82\" title=\"0.014\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.92%); opacity: 0.85\" title=\"0.030\">l</span><span style=\"background-color: hsl(120, 100.00%, 82.28%); opacity: 0.86\" title=\"0.038\">i</span><span style=\"background-color: hsl(120, 100.00%, 84.14%); opacity: 0.85\" title=\"0.032\">f</span><span style=\"background-color: hsl(120, 100.00%, 87.94%); opacity: 0.84\" title=\"0.022\">e</span><span style=\"background-color: hsl(0, 100.00%, 96.53%); opacity: 0.81\" title=\"-0.004\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.57%); opacity: 0.84\" title=\"-0.023\">s</span><span style=\"background-color: hsl(0, 100.00%, 87.04%); opacity: 0.84\" title=\"-0.024\">k</span><span style=\"background-color: hsl(0, 100.00%, 87.62%); opacity: 0.84\" title=\"-0.023\">i</span><span style=\"background-color: hsl(0, 100.00%, 91.20%); opacity: 0.82\" title=\"-0.014\">p</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Positive' if test_df['is_positive'].iloc[6] else 'Negative')\n",
    "eli5.show_prediction(clf, test_df['review_lem'].iloc[6], vec = vect, \n",
    "                     targets=['positive'], target_names=['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b6f62da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748,\n",
       " 'tfidf_vect_n13': 0.86748,\n",
       " 'tfidf_vect_n22': 0.62112,\n",
       " 'tfidf_vect_nc26': 0.88748,\n",
       " 'tfidf_vect_nc26_lem': 0.87372}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review_lem'], train_df['is_positive'], test_df['review_lem'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(analyzer='char', ngram_range=(2, 6), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_nc26_lem'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d28179",
   "metadata": {},
   "source": [
    "n-граммы символов хорошо подняли точность, а вот лемматизация в данном случае ее, наоборот, ухудшила"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db700aef",
   "metadata": {},
   "source": [
    "#### stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "795c2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21c122ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review_stem'] = train_df['review'].apply(lambda text: stem(text, stemmer))\n",
    "test_df['review_stem'] = test_df['review'].apply(lambda text: stem(text, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e61792de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748,\n",
       " 'tfidf_vect_n13': 0.86748,\n",
       " 'tfidf_vect_n22': 0.62112,\n",
       " 'tfidf_vect_nc26': 0.88748,\n",
       " 'tfidf_vect_nc26_lem': 0.87372,\n",
       " 'tfidf_vect_stem': 0.86948}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review_stem'], train_df['is_positive'], test_df['review_stem'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(ngram_range=(1, 1), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_stem'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ce552",
   "metadata": {},
   "source": [
    "стемминг сработал чуть лучше лемматизации на униграммах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64b82a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748,\n",
       " 'tfidf_vect_n13': 0.86748,\n",
       " 'tfidf_vect_n22': 0.62112,\n",
       " 'tfidf_vect_nc26': 0.88748,\n",
       " 'tfidf_vect_nc26_lem': 0.87372,\n",
       " 'tfidf_vect_stem': 0.86948,\n",
       " 'tfidf_vect_n12_stem': 0.87136}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review_stem'], train_df['is_positive'], test_df['review_stem'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(ngram_range=(1, 2), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_n12_stem'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30d850de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748,\n",
       " 'tfidf_vect_n13': 0.86748,\n",
       " 'tfidf_vect_n22': 0.62112,\n",
       " 'tfidf_vect_nc26': 0.88748,\n",
       " 'tfidf_vect_nc26_lem': 0.87372,\n",
       " 'tfidf_vect_stem': 0.86948,\n",
       " 'tfidf_vect_n12_stem': 0.87136,\n",
       " 'tfidf_vect_nс26_stem': 0.87272}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review_stem'], train_df['is_positive'], test_df['review_stem'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(analyzer='char', ngram_range=(2, 6), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_nс26_stem'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a7c37",
   "metadata": {},
   "source": [
    "стемминг не настолько ухудшил результат на символах как лемматизация, но результат все равно ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3883fc",
   "metadata": {},
   "source": [
    "#### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7aeb2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_docs.pkl', 'rb') as f:\n",
    "#     train_docs = pickle.load(f)\n",
    "    \n",
    "# with open('test_docs.pkl', 'rb') as f:\n",
    "#     test_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f9cbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"textcat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "642c35e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_person(text):\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    d = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == 'PERSON':\n",
    "            d.append(token.ent_type_)\n",
    "        else:\n",
    "            d.append(token.text)\n",
    "    return ' '.join(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea9a43b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dreamgirls despite its fistful of PERSON wins in an incredibly weak year on Broadway has never been what one would call a jewel in the crown of stage musicals However that is not to say that in the right cinematic hands it could not be fleshed out and polished into something worthwhile onscreen Unfortunately what transfers to the screen is basically a slavishly faithful version of the stage hit with all of its inherent weaknesses intact First the score has never been one of the strong points of this production and the film does not change that factor There are lots of songs perhaps too many but few of them are especially memorable The closest any come to catchy tunes are the title song and One Night Only   the much acclaimed And I Am Telling You That I Am Not Going is less a great song than it is a dramatic set piece for the character of PERSON PERSON PERSON The film is slick and technically wellproduced but the story and characters are surprisingly thin and lacking in any resonance There is some interest in the opening moments watching PERSON PERSON Svengalilike manager manipulate his acts to the top but that takes a back seat in the latter portion of the film when the story conveniently tries to cast him as a villain despite his having been right from a business standpoint for a good majority of the film PERSON PERSON is lovely and sings her songs perfectly well but is stuck with a character who is basically all surface glitz PERSON PERSON PERSON as the third member of the Dreamgirls trio literally has nothing to do for the entire film PERSON PERSON acquits himself well as a singer obviously based on PERSON PERSON but the role is not especially meaty and ultimately has little impact Foxx would seem ideal casting but he seems oddly withdrawn and bored The films biggest selling point is surely former American Idol contestantOscar winner PERSON PERSON in the central role of Effie White the temperamental singer who gets booted from the group and makes a triumphant closing act return For me Effie has always been a big problem in both the show and the movie The film obviously wants you to feel sorry for her and rather hamhandedly takes her side but I have never been sure that this character deserves that kind of devotion From the start Effie conducts herself for the most part like an obnoxious egotistical selfcentered diva who is more interested in what everyone else can do for her rather than having much vested interest in the group of which she is a part When she is booted from the group for her unprofessionalism and bad attitude the charges are more than wellfounded but the stage showfilm seem to think Effie should be cut unlimited slack simply because she has a great voice Even though the film tries to soften some of Effies harder edges to make her more likable the charges still stand Her story becomes more manipulative by suggesting she should have our further sympathy because she is an unwed mother struggling to raise her daughter   using the implication that much like the talent card motherhood immediately makes any behavior excusable Indeed the only big effort the film makes to show Effies mothering is to tell us about it and then include a scene where she barks at her daughter in the unemployment office insists that the girl has \" no father \" and then refuse to look for gainful employment to support them since singing is all she knows In the hands of a skillful actress the gaps could perhaps have been remedied with technique and charisma Unfortunately PERSON is not that actress She sings well but the dialogdriven moments do not come naturally to her nor do high emotional moments Effies signature moment the aforementioned And I Am Telling You number is wellsung by PERSON but emotionally flat in the acting department Effie is supposed to expressing her rage and desperation at her predicament but PERSON comes off as a cabaret performer belting out a hot number All in all not quite the emotional highlight one expects The latter portion of the film is basically a predictable melange of events that maneuver Foxx into Hudsons earlier position and allow her to strut back in and lord it over everyone Foxxs criminal offenses in the film are undoubtedly par for the course of many struggling record producers but the films seeming implication that he has it coming because he helped usher in the disco era is rather ridiculous not to mention pretentious and condescending particularly coming from a film with all of the depth of a puddle The end result is a faithful rendition of the stage hit drained of emotion energy or anything that can be described as dynamic'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_person(train_df['review'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c22de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['review_ner'] = train_df['review'].apply(lambda text: replace_person(text))\n",
    "test_df['review_ner'] = test_df['review'].apply(lambda text: replace_person(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bb8ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_processed.csv')\n",
    "test_df.to_csv('test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd283651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snetkova\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:391: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['_ссылка', 'интерфакс', 'как_сообщили_риа_', 'новости', 'передает_риа_', 'сообщает_', 'сообщает_риа_', 'хотел'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748,\n",
       " 'tfidf_vect_n13': 0.86748,\n",
       " 'tfidf_vect_n22': 0.62112,\n",
       " 'tfidf_vect_nc26': 0.88748,\n",
       " 'tfidf_vect_nc26_lem': 0.87372,\n",
       " 'tfidf_vect_stem': 0.86948,\n",
       " 'tfidf_vect_n12_stem': 0.87136,\n",
       " 'tfidf_vect_nс26_stem': 0.87272,\n",
       " 'tfidf_vect_n12_ner': 0.86644}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review_ner'], train_df['is_positive'], test_df['review_ner'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(ngram_range=(1, 2), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_n12_ner'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f570c37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keywords': 0.71224,\n",
       " 'count_vect': 0.85692,\n",
       " 'count_vect_lem': 0.85692,\n",
       " 'tfidf_vect': 0.8666,\n",
       " 'tfidf_vect_lem': 0.8666,\n",
       " 'tfidf_vect_n12': 0.86748,\n",
       " 'tfidf_vect_n13': 0.86748,\n",
       " 'tfidf_vect_n22': 0.62112,\n",
       " 'tfidf_vect_nc26': 0.88748,\n",
       " 'tfidf_vect_nc26_lem': 0.87372,\n",
       " 'tfidf_vect_stem': 0.86948,\n",
       " 'tfidf_vect_n12_stem': 0.87136,\n",
       " 'tfidf_vect_nс26_stem': 0.87272,\n",
       " 'tfidf_vect_n12_ner': 0.86644,\n",
       " 'tfidf_vect_nс26_ner': 0.8856}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, clf, vect = get_accuracy(train_df['review_ner'], train_df['is_positive'], test_df['review_ner'], test_df['is_positive'], LogisticRegression(), TfidfVectorizer(analyzer='char', ngram_range=(2, 6), stop_words = stopword_en, min_df = 0.01))\n",
    "res['tfidf_vect_nс26_ner'] = acc\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0620f9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_nc26</th>\n",
       "      <td>0.88748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_nс26_ner</th>\n",
       "      <td>0.88560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_nc26_lem</th>\n",
       "      <td>0.87372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_nс26_stem</th>\n",
       "      <td>0.87272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n12_stem</th>\n",
       "      <td>0.87136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_stem</th>\n",
       "      <td>0.86948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n12</th>\n",
       "      <td>0.86748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n13</th>\n",
       "      <td>0.86748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect</th>\n",
       "      <td>0.86660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_lem</th>\n",
       "      <td>0.86660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n12_ner</th>\n",
       "      <td>0.86644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_vect</th>\n",
       "      <td>0.85692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_vect_lem</th>\n",
       "      <td>0.85692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keywords</th>\n",
       "      <td>0.71224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n22</th>\n",
       "      <td>0.62112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy\n",
       "tfidf_vect_nc26        0.88748\n",
       "tfidf_vect_nс26_ner    0.88560\n",
       "tfidf_vect_nc26_lem    0.87372\n",
       "tfidf_vect_nс26_stem   0.87272\n",
       "tfidf_vect_n12_stem    0.87136\n",
       "tfidf_vect_stem        0.86948\n",
       "tfidf_vect_n12         0.86748\n",
       "tfidf_vect_n13         0.86748\n",
       "tfidf_vect             0.86660\n",
       "tfidf_vect_lem         0.86660\n",
       "tfidf_vect_n12_ner     0.86644\n",
       "count_vect             0.85692\n",
       "count_vect_lem         0.85692\n",
       "keywords               0.71224\n",
       "tfidf_vect_n22         0.62112"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(res, orient='index', columns = ['accuracy']).sort_values(by = 'accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e14f10",
   "metadata": {},
   "source": [
    "Самые высокие результаты у tfidf по символам, замена имен на тэг дала достаточно неплохой результат"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026518f",
   "metadata": {},
   "source": [
    "#### neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db0465f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_processed.csv\", index_col = 0, encoding = 'utf8')\n",
    "test_df = pd.read_csv(\"test_processed.csv\", index_col = 0, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7f88fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2450"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(s.split()) for s in train_df.review])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5844ab46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words count 20923\n"
     ]
    }
   ],
   "source": [
    "words_counter = Counter((word for text in train_df.review for word in text.lower().split()))\n",
    "\n",
    "word2idx = {\n",
    "    '': 0,\n",
    "    '<unk>': 1\n",
    "}\n",
    "for word, count in words_counter.most_common():\n",
    "    if count < 10:\n",
    "        break\n",
    "        \n",
    "    word2idx[word] = len(word2idx)\n",
    "    \n",
    "print('Words count', len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b05add98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 331886),\n",
       " ('and', 162232),\n",
       " ('a', 161580),\n",
       " ('of', 145327),\n",
       " ('to', 135064),\n",
       " ('is', 106975),\n",
       " ('in', 92987),\n",
       " ('it', 77816),\n",
       " ('i', 75260),\n",
       " ('this', 75246),\n",
       " ('that', 69462),\n",
       " ('was', 48090),\n",
       " ('as', 46645),\n",
       " ('for', 43993),\n",
       " ('with', 43929),\n",
       " ('movie', 42407),\n",
       " ('but', 41728),\n",
       " ('film', 38092),\n",
       " ('on', 33596),\n",
       " ('not', 30226),\n",
       " ('are', 29337),\n",
       " ('you', 29326),\n",
       " ('his', 29249),\n",
       " ('have', 27682),\n",
       " ('be', 26680),\n",
       " ('he', 26613),\n",
       " ('one', 25626),\n",
       " ('its', 24919),\n",
       " ('at', 23351),\n",
       " ('all', 23275),\n",
       " ('by', 22358),\n",
       " ('an', 21456),\n",
       " ('they', 20902),\n",
       " ('from', 20408),\n",
       " ('who', 20299),\n",
       " ('so', 19863),\n",
       " ('like', 19644),\n",
       " ('her', 18242),\n",
       " ('or', 17607),\n",
       " ('just', 17571),\n",
       " ('about', 17302),\n",
       " ('has', 16724),\n",
       " ('if', 16510),\n",
       " ('out', 16431),\n",
       " ('some', 15667),\n",
       " ('there', 15444),\n",
       " ('what', 14990),\n",
       " ('good', 14504),\n",
       " ('more', 14145),\n",
       " ('when', 14053),\n",
       " ('very', 13980),\n",
       " ('even', 12503),\n",
       " ('she', 12458),\n",
       " ('my', 12308),\n",
       " ('up', 12222),\n",
       " ('no', 12218),\n",
       " ('would', 12134),\n",
       " ('time', 12035),\n",
       " ('which', 11865),\n",
       " ('only', 11812),\n",
       " ('really', 11672),\n",
       " ('story', 11553),\n",
       " ('their', 11355),\n",
       " ('had', 11269),\n",
       " ('were', 11266),\n",
       " ('see', 11223),\n",
       " ('can', 11055),\n",
       " ('me', 10480),\n",
       " ('than', 9842),\n",
       " ('we', 9723),\n",
       " ('much', 9654),\n",
       " ('well', 9511),\n",
       " ('been', 9255),\n",
       " ('get', 9159),\n",
       " ('will', 9145),\n",
       " ('also', 9093),\n",
       " ('into', 9082),\n",
       " ('other', 9029),\n",
       " ('because', 8979),\n",
       " ('people', 8942),\n",
       " ('do', 8938),\n",
       " ('bad', 8926),\n",
       " ('great', 8908),\n",
       " ('first', 8856),\n",
       " ('him', 8753),\n",
       " ('most', 8737),\n",
       " ('how', 8703),\n",
       " ('dont', 8397),\n",
       " ('made', 8018),\n",
       " ('then', 7980),\n",
       " ('movies', 7888),\n",
       " ('them', 7885),\n",
       " ('way', 7836),\n",
       " ('films', 7822),\n",
       " ('could', 7719),\n",
       " ('make', 7715),\n",
       " ('too', 7637),\n",
       " ('any', 7633),\n",
       " ('after', 7515),\n",
       " ('characters', 7394),\n",
       " ('think', 7246),\n",
       " ('watch', 6857),\n",
       " ('many', 6649),\n",
       " ('two', 6633),\n",
       " ('seen', 6624),\n",
       " ('being', 6572),\n",
       " ('character', 6565),\n",
       " ('never', 6411),\n",
       " ('little', 6339),\n",
       " ('acting', 6332),\n",
       " ('plot', 6298),\n",
       " ('best', 6265),\n",
       " ('where', 6232),\n",
       " ('did', 6226),\n",
       " ('love', 6132),\n",
       " ('know', 6070),\n",
       " ('life', 6012),\n",
       " ('show', 5981),\n",
       " ('does', 5899),\n",
       " ('ever', 5850),\n",
       " ('better', 5639),\n",
       " ('your', 5614),\n",
       " ('still', 5557),\n",
       " ('over', 5537),\n",
       " ('off', 5492),\n",
       " ('end', 5490),\n",
       " ('these', 5384),\n",
       " ('here', 5345),\n",
       " ('say', 5340),\n",
       " ('while', 5263),\n",
       " ('scene', 5254),\n",
       " ('why', 5146),\n",
       " ('scenes', 5139),\n",
       " ('such', 5104),\n",
       " ('man', 5029),\n",
       " ('go', 4957),\n",
       " ('should', 4941),\n",
       " ('something', 4940),\n",
       " ('through', 4923),\n",
       " ('back', 4747),\n",
       " ('those', 4669),\n",
       " ('im', 4653),\n",
       " ('doesnt', 4561),\n",
       " ('watching', 4551),\n",
       " ('years', 4522),\n",
       " ('though', 4471),\n",
       " ('real', 4437),\n",
       " ('now', 4414),\n",
       " ('thing', 4397),\n",
       " ('actors', 4392),\n",
       " ('didnt', 4356),\n",
       " ('another', 4283),\n",
       " ('actually', 4214),\n",
       " ('before', 4211),\n",
       " ('makes', 4182),\n",
       " ('work', 4181),\n",
       " ('nothing', 4180),\n",
       " ('new', 4177),\n",
       " ('funny', 4132),\n",
       " ('find', 4108),\n",
       " ('s', 4107),\n",
       " ('few', 4062),\n",
       " ('same', 4020),\n",
       " ('look', 4014),\n",
       " ('going', 4009),\n",
       " ('old', 3996),\n",
       " ('part', 3954),\n",
       " ('every', 3951),\n",
       " ('lot', 3949),\n",
       " ('us', 3935),\n",
       " ('again', 3868),\n",
       " ('director', 3814),\n",
       " ('cast', 3730),\n",
       " ('quite', 3713),\n",
       " ('cant', 3713),\n",
       " ('thats', 3693),\n",
       " ('want', 3685),\n",
       " ('things', 3650),\n",
       " ('pretty', 3625),\n",
       " ('seems', 3610),\n",
       " ('got', 3575),\n",
       " ('around', 3569),\n",
       " ('young', 3567),\n",
       " ('world', 3497),\n",
       " ('fact', 3490),\n",
       " ('however', 3486),\n",
       " ('down', 3478),\n",
       " ('take', 3445),\n",
       " ('enough', 3412),\n",
       " ('both', 3381),\n",
       " ('between', 3359),\n",
       " ('may', 3349),\n",
       " ('give', 3347),\n",
       " ('ive', 3327),\n",
       " ('original', 3323),\n",
       " ('own', 3319),\n",
       " ('thought', 3305),\n",
       " ('series', 3270),\n",
       " ('big', 3267),\n",
       " ('horror', 3264),\n",
       " ('without', 3236),\n",
       " ('gets', 3219),\n",
       " ('always', 3211),\n",
       " ('long', 3194),\n",
       " ('isnt', 3169),\n",
       " ('times', 3168),\n",
       " ('right', 3167),\n",
       " ('saw', 3142),\n",
       " ('come', 3132),\n",
       " ('role', 3127),\n",
       " ('almost', 3095),\n",
       " ('least', 3095),\n",
       " ('interesting', 3092),\n",
       " ('point', 3090),\n",
       " ('whole', 3061),\n",
       " ('action', 3044),\n",
       " ('theres', 3040),\n",
       " ('must', 3031),\n",
       " ('bit', 3027),\n",
       " ('comedy', 3004),\n",
       " ('family', 2984),\n",
       " ('done', 2977),\n",
       " ('script', 2959),\n",
       " ('music', 2945),\n",
       " ('minutes', 2930),\n",
       " ('anything', 2913),\n",
       " ('might', 2889),\n",
       " ('last', 2880),\n",
       " ('since', 2877),\n",
       " ('hes', 2873),\n",
       " ('performance', 2864),\n",
       " ('far', 2864),\n",
       " ('\"the', 2862),\n",
       " ('feel', 2844),\n",
       " ('probably', 2826),\n",
       " ('guy', 2819),\n",
       " ('am', 2793),\n",
       " ('kind', 2731),\n",
       " ('rather', 2727),\n",
       " ('yet', 2696),\n",
       " ('away', 2694),\n",
       " ('worst', 2677),\n",
       " ('sure', 2647),\n",
       " ('fun', 2602),\n",
       " ('tv', 2588),\n",
       " ('making', 2575),\n",
       " ('each', 2570),\n",
       " ('found', 2562),\n",
       " ('anyone', 2558),\n",
       " ('woman', 2550),\n",
       " ('played', 2537),\n",
       " ('having', 2530),\n",
       " ('girl', 2522),\n",
       " ('although', 2489),\n",
       " ('course', 2479),\n",
       " ('believe', 2476),\n",
       " ('our', 2474),\n",
       " ('comes', 2469),\n",
       " ('trying', 2460),\n",
       " ('especially', 2435),\n",
       " ('goes', 2420),\n",
       " ('day', 2416),\n",
       " ('shows', 2400),\n",
       " ('looks', 2393),\n",
       " ('hard', 2384),\n",
       " ('different', 2351),\n",
       " ('put', 2333),\n",
       " ('wasnt', 2331),\n",
       " ('place', 2325),\n",
       " ('reason', 2293),\n",
       " ('book', 2286),\n",
       " ('ending', 2284),\n",
       " ('sense', 2280),\n",
       " ('money', 2274),\n",
       " ('maybe', 2266),\n",
       " ('once', 2263),\n",
       " ('set', 2262),\n",
       " ('everything', 2260),\n",
       " ('screen', 2258),\n",
       " ('worth', 2255),\n",
       " ('main', 2246),\n",
       " ('looking', 2242),\n",
       " ('true', 2228),\n",
       " ('job', 2228),\n",
       " ('watched', 2221),\n",
       " ('someone', 2216),\n",
       " ('plays', 2216),\n",
       " ('dvd', 2201),\n",
       " ('actor', 2199),\n",
       " ('together', 2187),\n",
       " ('said', 2175),\n",
       " ('seem', 2170),\n",
       " ('takes', 2162),\n",
       " ('instead', 2162),\n",
       " ('three', 2154),\n",
       " ('later', 2146),\n",
       " ('himself', 2138),\n",
       " ('during', 2126),\n",
       " ('play', 2124),\n",
       " ('beautiful', 2122),\n",
       " ('version', 2119),\n",
       " ('audience', 2116),\n",
       " ('john', 2116),\n",
       " ('effects', 2111),\n",
       " ('everyone', 2103),\n",
       " ('seeing', 2076),\n",
       " ('left', 2064),\n",
       " ('excellent', 2052),\n",
       " ('special', 2024),\n",
       " ('idea', 2016),\n",
       " ('shot', 1967),\n",
       " ('night', 1966),\n",
       " ('simply', 1961),\n",
       " ('nice', 1954),\n",
       " ('wife', 1953),\n",
       " ('american', 1941),\n",
       " ('house', 1937),\n",
       " ('read', 1907),\n",
       " ('else', 1906),\n",
       " ('year', 1905),\n",
       " ('completely', 1880),\n",
       " ('youre', 1879),\n",
       " ('less', 1876),\n",
       " ('help', 1872),\n",
       " ('second', 1865),\n",
       " ('fan', 1859),\n",
       " ('kids', 1858),\n",
       " ('high', 1856),\n",
       " ('poor', 1848),\n",
       " ('used', 1840),\n",
       " ('given', 1837),\n",
       " ('either', 1826),\n",
       " ('black', 1826),\n",
       " ('try', 1814),\n",
       " ('war', 1812),\n",
       " ('father', 1811),\n",
       " ('performances', 1798),\n",
       " ('enjoy', 1796),\n",
       " ('mind', 1796),\n",
       " ('need', 1795),\n",
       " ('rest', 1792),\n",
       " ('friends', 1788),\n",
       " ('use', 1785),\n",
       " ('short', 1781),\n",
       " ('classic', 1769),\n",
       " ('star', 1768),\n",
       " ('boring', 1766),\n",
       " ('home', 1766),\n",
       " ('death', 1764),\n",
       " ('wrong', 1759),\n",
       " ('until', 1756),\n",
       " ('along', 1745),\n",
       " ('truly', 1738),\n",
       " ('men', 1721),\n",
       " ('half', 1717),\n",
       " ('production', 1712),\n",
       " ('hollywood', 1699),\n",
       " ('tell', 1695),\n",
       " ('line', 1685),\n",
       " ('remember', 1679),\n",
       " ('next', 1679),\n",
       " ('women', 1673),\n",
       " ('start', 1671),\n",
       " ('came', 1671),\n",
       " ('couple', 1667),\n",
       " ('recommend', 1666),\n",
       " ('perhaps', 1656),\n",
       " ('others', 1648),\n",
       " ('awful', 1642),\n",
       " ('wonderful', 1640),\n",
       " ('understand', 1638),\n",
       " ('moments', 1637),\n",
       " ('episode', 1628),\n",
       " ('stupid', 1628),\n",
       " ('mean', 1623),\n",
       " ('full', 1611),\n",
       " ('terrible', 1609),\n",
       " ('let', 1606),\n",
       " ('getting', 1602),\n",
       " ('camera', 1599),\n",
       " ('playing', 1599),\n",
       " ('stars', 1593),\n",
       " ('keep', 1588),\n",
       " ('often', 1580),\n",
       " ('dead', 1579),\n",
       " ('doing', 1576),\n",
       " ('definitely', 1573),\n",
       " ('gives', 1571),\n",
       " ('small', 1558),\n",
       " ('video', 1556),\n",
       " ('early', 1543),\n",
       " ('itself', 1541),\n",
       " ('become', 1535),\n",
       " ('sex', 1534),\n",
       " ('lines', 1529),\n",
       " ('perfect', 1529),\n",
       " ('name', 1526),\n",
       " ('felt', 1519),\n",
       " ('finally', 1519),\n",
       " ('face', 1514),\n",
       " ('dialogue', 1513),\n",
       " ('school', 1511),\n",
       " ('person', 1511),\n",
       " ('supposed', 1508),\n",
       " ('couldnt', 1505),\n",
       " ('liked', 1505),\n",
       " ('human', 1502),\n",
       " ('piece', 1500),\n",
       " ('case', 1494),\n",
       " ('top', 1481),\n",
       " ('absolutely', 1481),\n",
       " ('title', 1466),\n",
       " ('entire', 1461),\n",
       " ('against', 1461),\n",
       " ('went', 1459),\n",
       " ('budget', 1457),\n",
       " ('certainly', 1453),\n",
       " ('lost', 1450),\n",
       " ('head', 1449),\n",
       " ('waste', 1448),\n",
       " ('sort', 1448),\n",
       " ('written', 1447),\n",
       " ('yes', 1442),\n",
       " ('worse', 1438),\n",
       " ('style', 1432),\n",
       " ('shes', 1432),\n",
       " ('live', 1429),\n",
       " ('picture', 1427),\n",
       " ('hope', 1424),\n",
       " ('problem', 1423),\n",
       " ('overall', 1420),\n",
       " ('several', 1414),\n",
       " ('entertaining', 1413),\n",
       " ('loved', 1410),\n",
       " ('cinema', 1403),\n",
       " ('fans', 1400),\n",
       " ('beginning', 1389),\n",
       " ('id', 1378),\n",
       " ('becomes', 1376),\n",
       " ('care', 1365),\n",
       " ('seemed', 1363),\n",
       " ('throughout', 1361),\n",
       " ('lives', 1360),\n",
       " ('already', 1357),\n",
       " ('example', 1356),\n",
       " ('direction', 1354),\n",
       " ('despite', 1353),\n",
       " ('based', 1347),\n",
       " ('boy', 1347),\n",
       " ('evil', 1340),\n",
       " ('wanted', 1340),\n",
       " ('\\x96', 1339),\n",
       " ('unfortunately', 1334),\n",
       " ('mr', 1333),\n",
       " ('mother', 1322),\n",
       " ('guys', 1315),\n",
       " ('white', 1308),\n",
       " ('killer', 1307),\n",
       " ('fine', 1305),\n",
       " ('totally', 1302),\n",
       " ('friend', 1302),\n",
       " ('children', 1301),\n",
       " ('final', 1299),\n",
       " ('turn', 1297),\n",
       " ('wont', 1296),\n",
       " ('laugh', 1295),\n",
       " ('wants', 1294),\n",
       " ('drama', 1292),\n",
       " ('amazing', 1290),\n",
       " ('guess', 1290),\n",
       " ('dark', 1285),\n",
       " ('lead', 1279),\n",
       " ('sound', 1278),\n",
       " ('history', 1277),\n",
       " ('humor', 1275),\n",
       " ('writing', 1273),\n",
       " ('tries', 1269),\n",
       " ('youll', 1269),\n",
       " ('works', 1264),\n",
       " ('low', 1262),\n",
       " ('girls', 1262),\n",
       " ('called', 1262),\n",
       " ('past', 1247),\n",
       " ('quality', 1247),\n",
       " ('michael', 1246),\n",
       " ('under', 1246),\n",
       " ('enjoyed', 1243),\n",
       " ('turns', 1243),\n",
       " ('days', 1242),\n",
       " ('able', 1240),\n",
       " ('oh', 1226),\n",
       " ('theyre', 1226),\n",
       " ('behind', 1225),\n",
       " ('favorite', 1220),\n",
       " ('starts', 1217),\n",
       " ('gave', 1216),\n",
       " ('act', 1208),\n",
       " ('game', 1201),\n",
       " ('son', 1201),\n",
       " ('viewer', 1191),\n",
       " ('sometimes', 1189),\n",
       " ('horrible', 1185),\n",
       " ('flick', 1183),\n",
       " ('parts', 1183),\n",
       " ('side', 1181),\n",
       " ('ones', 1179),\n",
       " ('soon', 1176),\n",
       " ('expect', 1174),\n",
       " ('themselves', 1169),\n",
       " ('town', 1169),\n",
       " ('car', 1168),\n",
       " ('eyes', 1164),\n",
       " ('brilliant', 1164),\n",
       " ('actress', 1163),\n",
       " ('genre', 1163),\n",
       " ('kill', 1155),\n",
       " ('obviously', 1154),\n",
       " ('child', 1147),\n",
       " ('stories', 1146),\n",
       " ('stuff', 1146),\n",
       " ('directed', 1144),\n",
       " ('heart', 1141),\n",
       " ('thinking', 1141),\n",
       " ('myself', 1130),\n",
       " ('feeling', 1127),\n",
       " ('late', 1127),\n",
       " ('decent', 1126),\n",
       " ('highly', 1123),\n",
       " ('etc', 1117),\n",
       " ('close', 1112),\n",
       " ('art', 1105),\n",
       " ('says', 1104),\n",
       " ('heard', 1101),\n",
       " ('roles', 1098),\n",
       " ('run', 1098),\n",
       " ('except', 1097),\n",
       " ('took', 1097),\n",
       " ('cannot', 1096),\n",
       " ('hand', 1095),\n",
       " ('ill', 1095),\n",
       " ('matter', 1093),\n",
       " ('killed', 1091),\n",
       " ('fight', 1089),\n",
       " ('moment', 1087),\n",
       " ('hour', 1081),\n",
       " ('leave', 1077),\n",
       " ('happens', 1070),\n",
       " ('anyway', 1068),\n",
       " ('wouldnt', 1065),\n",
       " ('strong', 1064),\n",
       " ('city', 1062),\n",
       " ('extremely', 1060),\n",
       " ('police', 1059),\n",
       " ('kid', 1057),\n",
       " ('involved', 1056),\n",
       " ('particularly', 1053),\n",
       " ('happened', 1053),\n",
       " ('chance', 1051),\n",
       " ('lack', 1050),\n",
       " ('obvious', 1049),\n",
       " ('hell', 1047),\n",
       " ('attempt', 1045),\n",
       " ('told', 1040),\n",
       " ('experience', 1039),\n",
       " ('violence', 1038),\n",
       " ('james', 1034),\n",
       " ('living', 1031),\n",
       " ('blood', 1021),\n",
       " ('wonder', 1020),\n",
       " ('including', 1020),\n",
       " ('complete', 1020),\n",
       " ('happen', 1019),\n",
       " ('ago', 1013),\n",
       " ('daughter', 1012),\n",
       " ('voice', 1011),\n",
       " ('group', 1009),\n",
       " ('age', 1007),\n",
       " ('interest', 1006),\n",
       " ('save', 1005),\n",
       " ('alone', 1004),\n",
       " ('type', 1004),\n",
       " ('looked', 1004),\n",
       " ('score', 1003),\n",
       " ('none', 1001),\n",
       " ('coming', 999),\n",
       " ('simple', 996),\n",
       " ('please', 996),\n",
       " ('number', 993),\n",
       " ('exactly', 992),\n",
       " ('shown', 992),\n",
       " ('murder', 984),\n",
       " ('possible', 983),\n",
       " ('slow', 981),\n",
       " ('whose', 979),\n",
       " ('taken', 979),\n",
       " ('annoying', 978),\n",
       " ('god', 976),\n",
       " ('usually', 975),\n",
       " ('sad', 975),\n",
       " ('ok', 975),\n",
       " ('career', 975),\n",
       " ('brother', 973),\n",
       " ('crap', 972),\n",
       " ('hours', 972),\n",
       " ('cinematography', 970),\n",
       " ('across', 967),\n",
       " ('yourself', 967),\n",
       " ('ends', 965),\n",
       " ('released', 964),\n",
       " ('seriously', 963),\n",
       " ('running', 959),\n",
       " ('david', 957),\n",
       " ('stop', 957),\n",
       " ('usual', 955),\n",
       " ('somewhat', 955),\n",
       " ('musical', 955),\n",
       " ('opening', 954),\n",
       " ('today', 954),\n",
       " ('known', 953),\n",
       " ('gore', 952),\n",
       " ('started', 951),\n",
       " ('song', 950),\n",
       " ('relationship', 950),\n",
       " ('serious', 950),\n",
       " ('ridiculous', 949),\n",
       " ('hilarious', 949),\n",
       " ('finds', 948),\n",
       " ('hit', 942),\n",
       " ('huge', 940),\n",
       " ('opinion', 939),\n",
       " ('change', 937),\n",
       " ('episodes', 936),\n",
       " ('saying', 934),\n",
       " ('shots', 933),\n",
       " ('wish', 932),\n",
       " ('jokes', 931),\n",
       " ('mostly', 929),\n",
       " ('scary', 927),\n",
       " ('reality', 926),\n",
       " ('english', 926),\n",
       " ('order', 923),\n",
       " ('robert', 921),\n",
       " ('novel', 921),\n",
       " ('taking', 919),\n",
       " ('lets', 918),\n",
       " ('major', 916),\n",
       " ('female', 913),\n",
       " ('talking', 911),\n",
       " ('body', 910),\n",
       " ('disappointed', 908),\n",
       " ('apparently', 908),\n",
       " ('level', 906),\n",
       " ('cut', 904),\n",
       " ('view', 904),\n",
       " ('rating', 903),\n",
       " ('\"', 903),\n",
       " ('due', 902),\n",
       " ('directors', 902),\n",
       " ('basically', 899),\n",
       " ('talent', 897),\n",
       " ('knows', 897),\n",
       " ('events', 896),\n",
       " ('clearly', 895),\n",
       " ('strange', 895),\n",
       " ('songs', 894),\n",
       " ('knew', 894),\n",
       " ('supporting', 894),\n",
       " ('important', 893),\n",
       " ('call', 892),\n",
       " ('cool', 892),\n",
       " ('husband', 891),\n",
       " ('turned', 885),\n",
       " ('attention', 882),\n",
       " ('documentary', 880),\n",
       " ('arent', 879),\n",
       " ('british', 879),\n",
       " ('tells', 878),\n",
       " ('easily', 875),\n",
       " ('problems', 874),\n",
       " ('local', 872),\n",
       " ('single', 872),\n",
       " ('room', 868),\n",
       " ('television', 867),\n",
       " ('word', 864),\n",
       " ('words', 864),\n",
       " ('power', 863),\n",
       " ('happy', 863),\n",
       " ('silly', 862),\n",
       " ('future', 861),\n",
       " ('sequence', 861),\n",
       " ('hero', 860),\n",
       " ('cheap', 859),\n",
       " ('bring', 858),\n",
       " ('four', 853),\n",
       " ('whether', 848),\n",
       " ('country', 846),\n",
       " ('viewers', 843),\n",
       " ('similar', 842),\n",
       " ('sets', 842),\n",
       " ('light', 840),\n",
       " ('beyond', 840),\n",
       " ('falls', 840),\n",
       " ('predictable', 838),\n",
       " ('miss', 838),\n",
       " ('king', 837),\n",
       " ('review', 836),\n",
       " ('modern', 835),\n",
       " ('jack', 834),\n",
       " ('paul', 834),\n",
       " ('appears', 833),\n",
       " ('upon', 832),\n",
       " ('needs', 832),\n",
       " ('enjoyable', 830),\n",
       " ('entertainment', 829),\n",
       " ('giving', 827),\n",
       " ('five', 827),\n",
       " ('richard', 823),\n",
       " ('comic', 821),\n",
       " ('storyline', 819),\n",
       " ('romantic', 817),\n",
       " ('whats', 816),\n",
       " ('george', 815),\n",
       " ('talk', 813),\n",
       " ('within', 813),\n",
       " ('havent', 810),\n",
       " ('mention', 809),\n",
       " ('animation', 809),\n",
       " ('feels', 808),\n",
       " ('nearly', 806),\n",
       " ('theater', 805),\n",
       " ('bunch', 803),\n",
       " ('add', 803),\n",
       " ('points', 801),\n",
       " ('lots', 797),\n",
       " ('dull', 797),\n",
       " ('moving', 797),\n",
       " ('surprised', 797),\n",
       " ('message', 797),\n",
       " ('sequel', 796),\n",
       " ('above', 796),\n",
       " ('herself', 792),\n",
       " ('using', 792),\n",
       " ('ways', 792),\n",
       " ('actual', 790),\n",
       " ('theme', 789),\n",
       " ('middle', 788),\n",
       " ('begins', 786),\n",
       " ('effort', 781),\n",
       " ('writer', 780),\n",
       " ('named', 780),\n",
       " ('ten', 780),\n",
       " ('among', 778),\n",
       " ('fantastic', 777),\n",
       " ('comments', 775),\n",
       " ('elements', 774),\n",
       " ('showing', 772),\n",
       " ('typical', 771),\n",
       " ('earth', 769),\n",
       " ('clear', 768),\n",
       " ('rock', 766),\n",
       " ('york', 766),\n",
       " ('tried', 766),\n",
       " ('easy', 765),\n",
       " ('team', 764),\n",
       " ('certain', 763),\n",
       " ('release', 762),\n",
       " ('avoid', 762),\n",
       " ('mystery', 760),\n",
       " ('dialog', 757),\n",
       " ('fall', 756),\n",
       " ('soundtrack', 755),\n",
       " ('season', 755),\n",
       " ('french', 754),\n",
       " ('near', 754),\n",
       " ('lady', 754),\n",
       " ('somehow', 751),\n",
       " ('parents', 751),\n",
       " ('thriller', 751),\n",
       " ('means', 751),\n",
       " ('stay', 751),\n",
       " ('hate', 750),\n",
       " ('leads', 749),\n",
       " ('form', 749),\n",
       " ('sorry', 746),\n",
       " ('famous', 746),\n",
       " ('editing', 746),\n",
       " ('doubt', 745),\n",
       " ('material', 745),\n",
       " ('working', 744),\n",
       " ('tale', 744),\n",
       " ('kept', 744),\n",
       " ('filmed', 743),\n",
       " ('check', 742),\n",
       " ('greatest', 741),\n",
       " ('straight', 740),\n",
       " ('weak', 739),\n",
       " ('buy', 739),\n",
       " ('viewing', 738),\n",
       " ('peter', 737),\n",
       " ('figure', 736),\n",
       " ('class', 736),\n",
       " ('feature', 735),\n",
       " ('brought', 735),\n",
       " ('general', 734),\n",
       " ('oscar', 732),\n",
       " ('hear', 730),\n",
       " ('minute', 730),\n",
       " ('particular', 729),\n",
       " ('sister', 729),\n",
       " ('period', 728),\n",
       " ('imagine', 724),\n",
       " ('atmosphere', 723),\n",
       " ('tom', 718),\n",
       " ('learn', 715),\n",
       " ('reviews', 715),\n",
       " ('follow', 715),\n",
       " ('sequences', 715),\n",
       " ('indeed', 713),\n",
       " ('realistic', 713),\n",
       " ('eventually', 713),\n",
       " ('lame', 711),\n",
       " ('fast', 710),\n",
       " ('move', 710),\n",
       " ('forget', 710),\n",
       " ('premise', 709),\n",
       " ('whos', 707),\n",
       " ('gone', 707),\n",
       " ('deal', 706),\n",
       " ('red', 706),\n",
       " ('decided', 704),\n",
       " ('eye', 703),\n",
       " ('believable', 702),\n",
       " ('possibly', 700),\n",
       " ('lee', 697),\n",
       " ('youve', 697),\n",
       " ('became', 697),\n",
       " ('third', 696),\n",
       " ('expected', 696),\n",
       " ('japanese', 691),\n",
       " ('difficult', 689),\n",
       " ('poorly', 689),\n",
       " ('whatever', 689),\n",
       " ('nature', 689),\n",
       " ('stand', 688),\n",
       " ('suspense', 688),\n",
       " ('de', 688),\n",
       " ('th', 687),\n",
       " ('subject', 686),\n",
       " ('writers', 685),\n",
       " ('crime', 685),\n",
       " ('sit', 684),\n",
       " ('sexual', 683),\n",
       " ('surprise', 683),\n",
       " ('nor', 679),\n",
       " ('screenplay', 677),\n",
       " ('average', 677),\n",
       " ('stage', 676),\n",
       " ('rent', 676),\n",
       " ('leaves', 675),\n",
       " ('wait', 674),\n",
       " ('begin', 673),\n",
       " ('needed', 672),\n",
       " ('reading', 670),\n",
       " ('note', 669),\n",
       " ('okay', 669),\n",
       " ('filmmakers', 669),\n",
       " ('killing', 667),\n",
       " ('question', 666),\n",
       " ('dance', 664),\n",
       " ('meets', 663),\n",
       " ('memorable', 662),\n",
       " ('situation', 662),\n",
       " ('superb', 661),\n",
       " ('truth', 660),\n",
       " ('otherwise', 659),\n",
       " ('credits', 659),\n",
       " ('earlier', 658),\n",
       " ('forced', 656),\n",
       " ('shame', 654),\n",
       " ('realize', 651),\n",
       " ('romance', 650),\n",
       " ('space', 650),\n",
       " ('unless', 650),\n",
       " ('die', 649),\n",
       " ('meet', 649),\n",
       " ('emotional', 648),\n",
       " ('zombie', 648),\n",
       " ('interested', 645),\n",
       " ('older', 644),\n",
       " ('footage', 644),\n",
       " ('write', 644),\n",
       " ('keeps', 643),\n",
       " ('comment', 641),\n",
       " ('features', 638),\n",
       " ('whom', 638),\n",
       " ('badly', 638),\n",
       " ('laughs', 638),\n",
       " ('dr', 636),\n",
       " ('towards', 635),\n",
       " ('ask', 634),\n",
       " ('disney', 633),\n",
       " ('joe', 633),\n",
       " ('weird', 632),\n",
       " ('quickly', 631),\n",
       " ('society', 631),\n",
       " ('sounds', 630),\n",
       " ('mess', 630),\n",
       " ('dramatic', 629),\n",
       " ('brings', 629),\n",
       " ('previous', 629),\n",
       " ('plus', 628),\n",
       " ('perfectly', 627),\n",
       " ('result', 627),\n",
       " ('directing', 626),\n",
       " ('worked', 626),\n",
       " ('boys', 624),\n",
       " ('incredibly', 623),\n",
       " ('development', 623),\n",
       " ('male', 622),\n",
       " ('personal', 621),\n",
       " ('imdb', 621),\n",
       " ('creepy', 620),\n",
       " ('admit', 619),\n",
       " ('plenty', 618),\n",
       " ('unique', 618),\n",
       " ('total', 618),\n",
       " ('appear', 616),\n",
       " ('beauty', 616),\n",
       " ('hands', 615),\n",
       " ('america', 614),\n",
       " ('effect', 613),\n",
       " ('cheesy', 613),\n",
       " ('apart', 613),\n",
       " ('hardly', 612),\n",
       " ('meant', 612),\n",
       " ('setting', 612),\n",
       " ('casting', 610),\n",
       " ('mark', 610),\n",
       " ('background', 607),\n",
       " ('leading', 607),\n",
       " ('crazy', 605),\n",
       " ('potential', 604),\n",
       " ('various', 604),\n",
       " ('deep', 604),\n",
       " ('create', 604),\n",
       " ('free', 603),\n",
       " ('brothers', 603),\n",
       " ('powerful', 602),\n",
       " ('dog', 601),\n",
       " ('remake', 600),\n",
       " ('fails', 598),\n",
       " ('scifi', 597),\n",
       " ('portrayed', 596),\n",
       " ('open', 595),\n",
       " ('forward', 592),\n",
       " ('hot', 590),\n",
       " ('street', 590),\n",
       " ('deserves', 589),\n",
       " ('inside', 589),\n",
       " ('reasons', 589),\n",
       " ('joke', 589),\n",
       " ('outside', 589),\n",
       " ('ideas', 588),\n",
       " ('battle', 588),\n",
       " ('expecting', 587),\n",
       " ('fairly', 585),\n",
       " ('manages', 583),\n",
       " ('attempts', 582),\n",
       " ('business', 581),\n",
       " ('masterpiece', 581),\n",
       " ('missing', 580),\n",
       " ('present', 579),\n",
       " ('return', 577),\n",
       " ('recently', 576),\n",
       " ('fighting', 576),\n",
       " ('fantasy', 575),\n",
       " ('unlike', 575),\n",
       " ('bill', 575),\n",
       " ('dumb', 574),\n",
       " ('pay', 574),\n",
       " ('further', 573),\n",
       " ('nudity', 573),\n",
       " ('success', 572),\n",
       " ('dream', 572),\n",
       " ('match', 571),\n",
       " ('william', 570),\n",
       " ('acted', 569),\n",
       " ('break', 569),\n",
       " ('political', 569),\n",
       " ('agree', 568),\n",
       " ('front', 568),\n",
       " ('copy', 568),\n",
       " ('telling', 567),\n",
       " ('box', 566),\n",
       " ('ben', 565),\n",
       " ('married', 565),\n",
       " ('christmas', 564),\n",
       " ('sadly', 564),\n",
       " ('following', 564),\n",
       " ('gay', 563),\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51fe757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e416c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(texts, word2idx, max_text_len):\n",
    "    data = np.zeros((len(texts), max_text_len), dtype=np.int)\n",
    "    \n",
    "    for inx, text in enumerate(texts):\n",
    "        result = []\n",
    "        for word in text.split():\n",
    "            if word in word2idx:\n",
    "                result.append(word2idx[word])\n",
    "        padding = [0]*(max_text_len - len(result))\n",
    "        data[inx] = np.array(padding + result[-max_text_len:], dtype=np.int)\n",
    "    return data\n",
    "\n",
    "X_train = convert(train_df.review, word2idx, max_len)\n",
    "X_test = convert(test_df.review, word2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a13ea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2450"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "084554e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2450, 128)         2678144   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,679,555\n",
      "Trainable params: 2,679,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word2idx), output_dim=128, input_length=X_train.shape[1]),\n",
    "    \n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(units=10, activation='relu'),\n",
    "    Dense(units=10, activation='relu'),\n",
    "    \n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1eaf84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 25s 126ms/step - loss: 0.5667 - accuracy: 0.7650\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 25s 128ms/step - loss: 0.2728 - accuracy: 0.8892\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 25s 127ms/step - loss: 0.1770 - accuracy: 0.9354\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 25s 128ms/step - loss: 0.1062 - accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21fb38da088>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "model.fit(X_train, train_df.is_positive, batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c83f917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 9s 45ms/step - loss: 0.3153 - accuracy: 0.8772\n"
     ]
    }
   ],
   "source": [
    "res['nn'] = model.evaluate(X_test, test_df.is_positive, batch_size = 128)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6de2fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_nc26</th>\n",
       "      <td>0.88748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_nс26_ner</th>\n",
       "      <td>0.88560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn</th>\n",
       "      <td>0.87724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_nc26_lem</th>\n",
       "      <td>0.87372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_nс26_stem</th>\n",
       "      <td>0.87272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n12_stem</th>\n",
       "      <td>0.87136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_stem</th>\n",
       "      <td>0.86948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n12</th>\n",
       "      <td>0.86748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n13</th>\n",
       "      <td>0.86748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect</th>\n",
       "      <td>0.86660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_lem</th>\n",
       "      <td>0.86660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n12_ner</th>\n",
       "      <td>0.86644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_vect</th>\n",
       "      <td>0.85692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_vect_lem</th>\n",
       "      <td>0.85692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keywords</th>\n",
       "      <td>0.71224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_vect_n22</th>\n",
       "      <td>0.62112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy\n",
       "tfidf_vect_nc26        0.88748\n",
       "tfidf_vect_nс26_ner    0.88560\n",
       "nn                     0.87724\n",
       "tfidf_vect_nc26_lem    0.87372\n",
       "tfidf_vect_nс26_stem   0.87272\n",
       "tfidf_vect_n12_stem    0.87136\n",
       "tfidf_vect_stem        0.86948\n",
       "tfidf_vect_n12         0.86748\n",
       "tfidf_vect_n13         0.86748\n",
       "tfidf_vect             0.86660\n",
       "tfidf_vect_lem         0.86660\n",
       "tfidf_vect_n12_ner     0.86644\n",
       "count_vect             0.85692\n",
       "count_vect_lem         0.85692\n",
       "keywords               0.71224\n",
       "tfidf_vect_n22         0.62112"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(res, orient='index', columns = ['accuracy']).sort_values(by = 'accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97db65",
   "metadata": {},
   "source": [
    "Сетка оказалась не самым лучшим вариантом по точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = Sequential([\n",
    "#     Embedding(input_dim=len(word2idx), output_dim=128, input_length=X_train.shape[1]),\n",
    "#     LSTM(units = 128, return_sequences=True),\n",
    "    \n",
    "#     Dense(units=1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# model2.summary()\n",
    "# model2.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67570d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "# model2.fit(X_train, train_df.is_positive, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.evaluate(X_test, test_df.is_positive, batch_size = 16)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd09905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
